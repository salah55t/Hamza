#!/usr/bin/env python
# -*- coding: utf-8 -*- # Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªØ±Ù…ÙŠØ²

import time
import os
import pandas as pd
import numpy as np
import psycopg2
from binance.client import Client
from binance import ThreadedWebsocketManager
from flask import Flask, request
from threading import Thread
import logging
import requests
import json
from decouple import config
from apscheduler.schedulers.background import BackgroundScheduler
from datetime import datetime, timedelta
# --- Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù„Ø§Ø²Ù…Ø© Ù„Ù€ Linear Regression ---
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error # MAE Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„ÙƒÙ† Ù…ÙÙŠØ¯
from sklearn.ensemble import GradientBoostingRegressor # For price prediction (optional) - Kept for compatibility if needed

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ----------------------
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('crypto_bot_ar.log', encoding='utf-8'), # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªØ±Ù…ÙŠØ² Ù„Ù„Ù…Ù„Ù
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ---------------------- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ© ----------------------
api_key = config('BINANCE_API_KEY')
api_secret = config('BINANCE_API_SECRET')
telegram_token = config('TELEGRAM_BOT_TOKEN')
chat_id = config('TELEGRAM_CHAT_ID')
db_url = config('DATABASE_URL')

logger.info(f" Ù…ÙØªØ§Ø­ Binance API: {'Ù…ÙˆØ¬ÙˆØ¯' if api_key else 'ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯'}")
logger.info(f" ØªÙˆÙƒÙ† ØªÙ„ÙŠØ¬Ø±Ø§Ù…: {telegram_token[:10]}...{'*' * (len(telegram_token)-10)}")
logger.info(f" Ù…Ø¹Ø±Ù Ø¯Ø±Ø¯Ø´Ø© ØªÙ„ÙŠØ¬Ø±Ø§Ù…: {chat_id}")
logger.info(f" Ø±Ø§Ø¨Ø· Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {'Ù…ÙˆØ¬ÙˆØ¯' if db_url else 'ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯'}")

# ---------------------- Ø«ÙˆØ§Ø¨Øª ÙˆØ¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© ----------------------
TRADE_VALUE = 10  # Ù‚ÙŠÙ…Ø© Ø§Ù„ØµÙÙ‚Ø© Ø§Ù„Ø«Ø§Ø¨ØªØ© Ø¨Ø§Ù„Ø¯ÙˆÙ„Ø§Ø±
MAX_OPEN_TRADES = 4 # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø© ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª
SIGNAL_GENERATION_TIMEFRAME = '1h' # Ø§Ù„ÙØ±ÙŠÙ… Ø§Ù„Ø²Ù…Ù†ÙŠ Ù„ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø¬Ø¯ÙŠØ¯Ø©
SIGNAL_GENERATION_LOOKBACK_DAYS = 4 # Ø¹Ø¯Ø¯ Ø£ÙŠØ§Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª
SIGNAL_TRACKING_TIMEFRAME = '15m' # Ø§Ù„ÙØ±ÙŠÙ… Ø§Ù„Ø²Ù…Ù†ÙŠ Ù„ØªØªØ¨Ø¹ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©
SIGNAL_TRACKING_LOOKBACK_DAYS = 2 # Ø¹Ø¯Ø¯ Ø£ÙŠØ§Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„ØªØªØ¨Ø¹ Ø§Ù„ØªÙˆØµÙŠØ§Øª

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ù…ØªØ­Ø±Ùƒ (ATR Trailing Stop)
TRAILING_STOP_ACTIVATION_PROFIT_PCT = 0.015 # Ù†Ø³Ø¨Ø© Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„ØªÙØ¹ÙŠÙ„ Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ (e.g., 1.5%)
TRAILING_STOP_ATR_MULTIPLIER = 2.0 # Ù…Ø¹Ø§Ù…Ù„ ATR Ù„ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§ÙØ© Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„
ENTRY_ATR_MULTIPLIER = 1.5 # Ù…Ø¹Ø§Ù…Ù„ ATR Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù‡Ø¯Ù ÙˆÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠ
MIN_PROFIT_MARGIN_PCT = 1.0 # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù‡Ø§Ù…Ø´ Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ÙÙŠ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© (%)
MIN_VOLUME_15M_USDT = 500000 # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ ÙÙŠ Ø¢Ø®Ø± 15 Ø¯Ù‚ÙŠÙ‚Ø©

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ----------------------
conn = None
cur = None

def init_db():
    global conn, cur
    retries = 5
    delay = 5
    for i in range(retries):
        try:
            logger.info(f"[DB] Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù…Ø­Ø§ÙˆÙ„Ø© {i+1}/{retries})...")
            conn = psycopg2.connect(db_url, connect_timeout=10)
            conn.autocommit = False # Ù…Ù‡Ù… Ù„Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø¢Ù…Ù†Ø©
            cur = conn.cursor()
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§ØŒ Ù…Ø¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­Ø¯Ø«Ø© ÙˆØ§Ù„Ù‚ÙŠÙˆØ¯
            cur.execute("""
                CREATE TABLE IF NOT EXISTS signals (
                    id SERIAL PRIMARY KEY,
                    symbol TEXT NOT NULL,
                    entry_price DOUBLE PRECISION NOT NULL,
                    initial_target DOUBLE PRECISION NOT NULL, -- Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø£ÙˆÙ„ÙŠ
                    initial_stop_loss DOUBLE PRECISION NOT NULL, -- ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠ
                    current_target DOUBLE PRECISION NOT NULL, -- Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø­Ø§Ù„ÙŠ (ÙŠÙ…ÙƒÙ† ØªØ­Ø¯ÙŠØ«Ù‡)
                    current_stop_loss DOUBLE PRECISION NOT NULL, -- ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø­Ø§Ù„ÙŠ (ÙŠÙ…ÙƒÙ† ØªØ­Ø¯ÙŠØ«Ù‡)
                    r2_score DOUBLE PRECISION, -- R2 score from freqtrade strategy (buy_score)
                    volume_15m DOUBLE PRECISION,
                    achieved_target BOOLEAN DEFAULT FALSE,
                    hit_stop_loss BOOLEAN DEFAULT FALSE,
                    closing_price DOUBLE PRECISION,
                    closed_at TIMESTAMP,
                    sent_at TIMESTAMP DEFAULT NOW(),
                    profit_percentage DOUBLE PRECISION,
                    profitable_stop_loss BOOLEAN DEFAULT FALSE,
                    is_trailing_active BOOLEAN DEFAULT FALSE,
                    predicted_price_lr DOUBLE PRECISION, -- *** NEW: Predicted price from Linear Regression
                    r2_score_lr DOUBLE PRECISION         -- *** NEW: R2 score from Linear Regression model
                )
            """)
            conn.commit() # ØªØ£ÙƒÙŠØ¯ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯ÙˆÙ„ ÙÙˆØ±Ø§Ù‹

            # --- Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø© ---
            new_columns = {
                "initial_target": "DOUBLE PRECISION",
                "initial_stop_loss": "DOUBLE PRECISION",
                "current_target": "DOUBLE PRECISION",
                "current_stop_loss": "DOUBLE PRECISION",
                "is_trailing_active": "BOOLEAN DEFAULT FALSE",
                "closing_price": "DOUBLE PRECISION",
                "predicted_price_lr": "DOUBLE PRECISION", # *** NEW
                "r2_score_lr": "DOUBLE PRECISION"        # *** NEW
            }
            table_changed = False
            for col_name, col_type in new_columns.items():
                 try:
                     cur.execute(f"ALTER TABLE signals ADD COLUMN {col_name} {col_type}")
                     conn.commit()
                     logger.info(f"âœ… [DB] ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù…ÙˆØ¯ '{col_name}' Ø¥Ù„Ù‰ Ø¬Ø¯ÙˆÙ„ 'signals'.")
                     table_changed = True
                 except psycopg2.Error as e:
                     if e.pgcode == '42701':  # duplicate_column
                         conn.rollback() # Important: Rollback the transaction
                         logger.debug(f"â„¹ï¸ [DB] Ø§Ù„Ø¹Ù…ÙˆØ¯ '{col_name}' Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„.")
                     else:
                         logger.error(f"âŒ [DB] ÙØ´Ù„ ÙÙŠ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù…ÙˆØ¯ '{col_name}': {e} (pgcode: {e.pgcode})")
                         conn.rollback()
                         raise

            not_null_columns = [
                "symbol", "entry_price", "initial_target", "initial_stop_loss",
                "current_target", "current_stop_loss"
            ]
            for col_name in not_null_columns:
                try:
                    cur.execute(f"ALTER TABLE signals ALTER COLUMN {col_name} SET NOT NULL")
                    conn.commit()
                    # logger.info(f"âœ… [DB] ØªÙ… Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø¹Ù…ÙˆØ¯ '{col_name}' ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚ÙŠØ¯ NOT NULL.") # Removed for brevity
                    table_changed = True # Assume change or check needed
                except psycopg2.Error as e:
                     if "is an identity column" in str(e) or "already set" in str(e):
                          conn.rollback()
                     elif e.pgcode == '42704': # undefined_object (column might not exist yet if alter failed above)
                         conn.rollback()
                     else:
                         logger.warning(f"âš ï¸ [DB] Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† ØªØ¹ÙŠÙŠÙ† NOT NULL Ù„Ù„Ø¹Ù…ÙˆØ¯ '{col_name}': {e}")
                         conn.rollback()
            if table_changed:
                 logger.info("âœ… [DB] ØªÙ… ØªØ­Ø¯ÙŠØ«/Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¨Ù†ÙŠØ© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­.")
            else:
                 logger.info("âœ… [DB] Ø¨Ù†ÙŠØ© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ø¯Ø«Ø©.")
            logger.info("âœ… [DB] ØªÙ… ØªØ£Ø³ÙŠØ³ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­.")
            return
        except (psycopg2.OperationalError, psycopg2.DatabaseError) as e:
            logger.error(f"âŒ [DB] ÙØ´Ù„Øª Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ {i+1}: {e}")
            if i < retries - 1:
                logger.info(f"[DB] Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø®Ù„Ø§Ù„ {delay} Ø«ÙˆØ§Ù†ÙŠ...")
                time.sleep(delay)
            else:
                logger.critical("âŒ [DB] ÙØ´Ù„Øª Ø¬Ù…ÙŠØ¹ Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„. Ø§Ù„Ø®Ø±ÙˆØ¬.")
                raise
        except Exception as e:
            logger.critical(f"âŒ [DB] Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            raise

def check_db_connection():
    global conn, cur
    try:
        if conn is None or conn.closed != 0:
             logger.warning("âš ï¸ [DB] Ø§Ù„Ø§ØªØµØ§Ù„ Ù…ØºÙ„Ù‚ Ø£Ùˆ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙ‡ÙŠØ¦Ø©...")
             init_db()
             return
        # Optional: Execute a simple query to truly test connection
        cur.execute("SELECT 1")
        # logger.debug("âœ… [DB] Connection check successful.") # Can be noisy
    except (psycopg2.InterfaceError, psycopg2.OperationalError) as e:
        logger.warning(f"âš ï¸ [DB] ØªÙ… ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø§ØªØµØ§Ù„ ({e}). Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙ‡ÙŠØ¦Ø©...")
        try:
            if cur: cur.close()
            if conn: conn.close()
            conn, cur = None, None
            init_db()
        except Exception as ex:
            logger.error(f"âŒ [DB] ÙØ´Ù„ ÙÙŠ Ø¥Ø¹Ø§Ø¯Ø© ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø¹Ø¯ ÙÙ‚Ø¯Ø§Ù†Ù‡: {ex}")
            raise
    except Exception as e:
        logger.error(f"âŒ [DB] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ ÙØ­Øµ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
        try:
            if cur: cur.close()
            if conn: conn.close()
            conn, cur = None, None
            init_db()
        except Exception as ex:
            logger.error(f"âŒ [DB] ÙØ´Ù„ ÙÙŠ Ø¥Ø¹Ø§Ø¯Ø© ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø¹Ø¯ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {ex}")
            raise

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø¹Ù…ÙŠÙ„ Binance ----------------------
try:
    client = Client(api_key, api_secret)
    client.ping()  # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„
    logger.info("âœ… [Binance] ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø¹Ù…ÙŠÙ„ Binance ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„.")
except Exception as e:
    logger.critical(f"âŒ [Binance] ÙØ´Ù„ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ø¹Ù…ÙŠÙ„ Binance: {e}. ØªØ­Ù‚Ù‚ Ù…Ù† Ù…ÙØ§ØªÙŠØ­ API ÙˆØ§Ù„Ø§ØªØµØ§Ù„.")
    raise

# ---------------------- Ø§Ø³ØªØ®Ø¯Ø§Ù… WebSocket Ù„ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠÙƒØ± ----------------------
ticker_data = {}  # Ù‚Ø§Ù…ÙˆØ³ Ù„ØªØ®Ø²ÙŠÙ† Ø£Ø­Ø¯Ø« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠÙƒØ± Ù„ÙƒÙ„ Ø²ÙˆØ¬

def handle_ticker_message(msg):
    """ÙŠØ¹Ø§Ù„Ø¬ Ø±Ø³Ø§Ø¦Ù„ WebSocket Ø§Ù„ÙˆØ§Ø±Ø¯Ø© ÙˆÙŠØ­Ø¯Ø« Ù‚Ø§Ù…ÙˆØ³ ticker_data."""
    try:
        if isinstance(msg, list):
            for m in msg:
                symbol = m.get('s')
                if symbol and 'USDT' in symbol:
                    ticker_data[symbol] = {
                        'c': m.get('c'),  # Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ
                        'h': m.get('h'),  # Ø£Ø¹Ù„Ù‰ Ø³Ø¹Ø± 24 Ø³Ø§Ø¹Ø©
                        'l': m.get('l'),  # Ø£Ø¯Ù†Ù‰ Ø³Ø¹Ø± 24 Ø³Ø§Ø¹Ø©
                        'v': m.get('v')   # Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„ÙƒÙ„ÙŠ Ù„Ù„Ø£ØµÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ 24 Ø³Ø§Ø¹Ø©
                    }
        elif isinstance(msg, dict) and 'stream' not in msg and 'e' in msg and msg['e'] == 'error':
            logger.error(f"âŒ [WS] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø±Ø³Ø§Ù„Ø© Ø®Ø·Ø£ Ù…Ù† WebSocket: {msg.get('m')}")
    except Exception as e:
        logger.error(f"âŒ [WS] Ø®Ø·Ø£ ÙÙŠ handle_ticker_message: {e}")
        logger.debug(f"Ø±Ø³Ø§Ù„Ø© WS Ø§Ù„ØªÙŠ Ø³Ø¨Ø¨Øª Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: {msg}")

def run_ticker_socket_manager():
    """ÙŠØ´ØºÙ„ Ù…Ø¯ÙŠØ± WebSocket Ø§Ù„Ø®Ø§Øµ Ø¨Ù€ Binance Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ø¯ÙŠØ«Ø§Øª Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ø­ÙŠØ©."""
    while True:
        try:
            logger.info("â„¹ï¸ [WS] Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ù…Ø¯ÙŠØ± WebSocket...")
            twm = ThreadedWebsocketManager(api_key=api_key, api_secret=api_secret)
            twm.start()
            twm.start_miniticker_socket(callback=handle_ticker_message)
            logger.info("âœ… [WS] ØªÙ… ØªÙˆØµÙŠÙ„ WebSocket Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ø§Ù„Ù…ÙŠÙ†ÙŠ-ØªÙŠÙƒØ±.")
            twm.join()
            logger.warning("âš ï¸ [WS] ØªÙˆÙ‚Ù Ù…Ø¯ÙŠØ± WebSocket. Ø³ÙŠØªÙ… Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„...")
        except Exception as e:
            logger.error(f"âŒ [WS] Ø®Ø·Ø£ ÙÙŠ ØªØ´ØºÙŠÙ„ Ù…Ø¯ÙŠØ± WebSocket: {e}. Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ Ø¨Ø¹Ø¯ ØªØ£Ø®ÙŠØ±...")
        time.sleep(15)

# ---------------------- Ø¯ÙˆØ§Ù„ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© ----------------------
# (Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©: calculate_ema, calculate_rsi_indicator, ..., detect_candlestick_patterns ÙƒÙ…Ø§ Ù‡ÙŠ)
# ... (Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù„Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© Ù…ÙˆØ¬ÙˆØ¯ Ù‡Ù†Ø§) ...
def calculate_ema(series, span):
    return series.ewm(span=span, adjust=False).mean()

def calculate_rsi_indicator(df, period=14):
    delta = df['close'].diff()
    gain = delta.clip(lower=0)
    loss = -delta.clip(upper=0)
    avg_gain = gain.rolling(window=period, min_periods=period).mean()
    avg_loss = loss.rolling(window=period, min_periods=period).mean().replace(0, np.nan)
    rs = avg_gain / avg_loss
    rsi = 100 - (100 / (1 + rs))
    return rsi

def calculate_atr_indicator(df, period=14):
    high_low = df['high'] - df['low']
    high_close = (df['high'] - df['close'].shift(1)).abs()
    low_close = (df['low'] - df['close'].shift(1)).abs()
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1, skipna=False)
    atr = tr.rolling(window=period, min_periods=period).mean()
    df['atr'] = atr
    return df

def calculate_macd(df, fast_period=10, slow_period=21, signal_period=8):
    df['ema_fast'] = calculate_ema(df['close'], fast_period)
    df['ema_slow'] = calculate_ema(df['close'], slow_period)
    df['macd'] = df['ema_fast'] - df['ema_slow']
    df['macd_signal'] = calculate_ema(df['macd'], signal_period)
    df['macd_hist'] = df['macd'] - df['macd_signal']
    return df

def calculate_kdj(df, period=14, k_period=3, d_period=3):
    low_min = df['low'].rolling(window=period).min()
    high_max = df['high'].rolling(window=period).max()
    rsv_denominator = (high_max - low_min).replace(0, np.nan)
    rsv = (df['close'] - low_min) / rsv_denominator * 100
    df['kdj_k'] = rsv.ewm(com=(k_period - 1), adjust=False).mean()
    df['kdj_d'] = df['kdj_k'].ewm(com=(d_period - 1), adjust=False).mean()
    df['kdj_j'] = 3 * df['kdj_k'] - 2 * df['kdj_d']
    return df

def calculate_adx(df, period=14):
    df['up_move'] = df['high'] - df['high'].shift(1)
    df['down_move'] = df['low'].shift(1) - df['low']
    df['+dm'] = np.where((df['up_move'] > df['down_move']) & (df['up_move'] > 0), df['up_move'], 0)
    df['-dm'] = np.where((df['down_move'] > df['up_move']) & (df['down_move'] > 0), df['down_move'], 0)
    tr = pd.concat([
        (df['high'] - df['low']),
        (df['high'] - df['close'].shift(1)).abs(),
        (df['low'] - df['close'].shift(1)).abs()
    ], axis=1).max(axis=1, skipna=False)
    atr = tr.ewm(alpha=1/period, adjust=False).mean().replace(0, np.nan)
    plus_di = 100 * (df['+dm'].ewm(alpha=1/period, adjust=False).mean() / atr)
    minus_di = 100 * (df['-dm'].ewm(alpha=1/period, adjust=False).mean() / atr)
    dx_denominator = (plus_di + minus_di).replace(0, np.nan)
    dx = 100 * (abs(plus_di - minus_di) / dx_denominator)
    adx = dx.ewm(alpha=1/period, adjust=False).mean()
    df['+di'] = plus_di
    df['-di'] = minus_di
    df['adx'] = adx
    return df

def is_hammer(row):
    open_price, high, low, close = row['open'], row['high'], row['low'], row['close']
    if None in [open_price, high, low, close]: return 0
    body = abs(close - open_price)
    candle_range = high - low
    if candle_range == 0: return 0
    lower_shadow = min(open_price, close) - low
    upper_shadow = high - max(open_price, close)
    if body > 0 and lower_shadow >= 2 * body and upper_shadow <= 0.3 * body:
        return 100
    return 0

def is_shooting_star(row):
    open_price, high, low, close = row['open'], row['high'], row['low'], row['close']
    if None in [open_price, high, low, close]: return 0
    body = abs(close - open_price)
    candle_range = high - low
    if candle_range == 0: return 0
    lower_shadow = min(open_price, close) - low
    upper_shadow = high - max(open_price, close)
    if body > 0 and upper_shadow >= 2 * body and lower_shadow <= 0.3 * body:
        return -100
    return 0

def compute_engulfing(df, idx):
    if idx == 0: return 0
    prev = df.iloc[idx - 1]
    curr = df.iloc[idx]
    if None in [prev['close'], prev['open'], curr['close'], curr['open']]: return 0
    if prev['close'] < prev['open'] and curr['close'] > curr['open']:
        if curr['open'] < prev['close'] and curr['close'] > prev['open']:
            return 100
    if prev['close'] > prev['open'] and curr['close'] < curr['open']:
        if curr['open'] > prev['close'] and curr['close'] < prev['open']:
            return -100
    return 0

def detect_candlestick_patterns(df):
    df['Hammer'] = df.apply(is_hammer, axis=1)
    df['ShootingStar'] = df.apply(is_shooting_star, axis=1)
    engulfing_values = [0] * len(df)
    if len(df) > 1:
        engulfing_values = [compute_engulfing(df, i) for i in range(len(df))]
    df['Engulfing'] = engulfing_values
    df['BullishSignal'] = df.apply(lambda row: 100 if (row['Hammer'] == 100 or row['Engulfing'] == 100) else 0, axis=1)
    df['BearishSignal'] = df.apply(lambda row: 100 if (row['ShootingStar'] == -100 or row['Engulfing'] == -100) else 0, axis=1)
    return df

# ---------------------- Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ----------------------
# (Ø¯ÙˆØ§Ù„ get_market_sentiment, get_fear_greed_index, ml_predict_signal ÙƒÙ…Ø§ Ù‡ÙŠ)
# ... (Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø¯ÙˆØ§Ù„ Ù…ÙˆØ¬ÙˆØ¯ Ù‡Ù†Ø§) ...
def ml_predict_signal(symbol, df):
    try:
        if df.empty or 'rsi' not in df.columns or 'adx' not in df.columns: return 0.5
        rsi = df['rsi'].iloc[-1]
        adx = df['adx'].iloc[-1]
        if pd.isna(rsi) or pd.isna(adx): return 0.5
        if rsi < 40 and adx > 25: return 0.80
        elif rsi > 65 and adx > 25: return 0.20
        else: return 0.5
    except IndexError: return 0.5
    except Exception as e:
        logger.error(f"âŒ [ML] Ø®Ø·Ø£ ÙÙŠ ml_predict_signal Ù„Ù„Ø²ÙˆØ¬ {symbol}: {e}")
        return 0.5

def get_market_sentiment(symbol):
    return 0.6 # Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù…Ø¤Ù‚ØªÙ‹Ø§

def get_fear_greed_index():
    try:
        url = "https://api.alternative.me/fng/?limit=1&format=json"
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        data = response.json()
        if data.get("data"):
            fng_value = float(data["data"][0].get("value", 50))
            fng_classification_en = data["data"][0].get("value_classification", "Neutral")
            fng_translations = {
                "Extreme Fear": "Ø®ÙˆÙ Ø´Ø¯ÙŠØ¯",
                "Fear": "Ø®ÙˆÙ",
                "Neutral": "Ù…Ø­Ø§ÙŠØ¯",
                "Greed": "Ø¬Ø´Ø¹",
                "Extreme Greed": "Ø¬Ø´Ø¹ Ø´Ø¯ÙŠØ¯"
            }
            fng_classification_ar = fng_translations.get(fng_classification_en, fng_classification_en)
            logger.info(f"âœ… [FNG] Ù…Ø¤Ø´Ø± Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø¬Ø´Ø¹: {fng_value:.0f} - {fng_classification_ar}")
            return fng_value, fng_classification_ar
        else:
            logger.warning("âš ï¸ [FNG] Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ø¤Ø´Ø± Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø¬Ø´Ø¹.")
            return 50.0, "Ù…Ø­Ø§ÙŠØ¯"
    except requests.exceptions.RequestException as e:
        logger.error(f"âŒ [FNG] Ø®Ø·Ø£ ÙÙŠ Ø·Ù„Ø¨ Ù…Ø¤Ø´Ø± Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø¬Ø´Ø¹: {e}")
        return 50.0, "Ø®Ø·Ø£"
    except Exception as e:
        logger.error(f"âŒ [FNG] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø¬Ù„Ø¨ Ù…Ø¤Ø´Ø± Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø¬Ø´Ø¹: {e}")
        return 50.0, "Ø®Ø·Ø£"

# ---------------------- Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Freqtrade Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø© (ÙƒÙØ¦Ø©) ----------------------
class FreqtradeStrategy:
    def populate_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        if len(df) < 50:
            logger.warning(f"âš ï¸ [Strategy] DataFrame Ù‚ØµÙŠØ± Ø¬Ø¯Ù‹Ø§ ({len(df)} Ø´Ù…Ø¹Ø©) Ù„Ø­Ø³Ø§Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª.")
            if all(col in df.columns for col in ['open', 'high', 'low', 'close']):
                 return df
            else:
                 return pd.DataFrame()
        try:
            df['ema5'] = calculate_ema(df['close'], 5)
            df['ema8'] = calculate_ema(df['close'], 8)
            df['ema21'] = calculate_ema(df['close'], 21)
            df['ema34'] = calculate_ema(df['close'], 34)
            df['ema50'] = calculate_ema(df['close'], 50)
            df['rsi'] = calculate_rsi_indicator(df)
            df['sma20'] = df['close'].rolling(window=20).mean()
            df['std20'] = df['close'].rolling(window=20).std()
            df['upper_band'] = df['sma20'] + (2.5 * df['std20'])
            df['lower_band'] = df['sma20'] - (2.5 * df['std20'])
            df = calculate_atr_indicator(df)
            df = calculate_macd(df)
            df = calculate_kdj(df)
            df = calculate_adx(df)
            df = detect_candlestick_patterns(df)
            initial_len = len(df)
            df = df.dropna()
            dropped_count = initial_len - len(df)
            if dropped_count > 0:
                logger.debug(f"â„¹ï¸ [Strategy] ØªÙ… Ø­Ø°Ù {dropped_count} ØµÙÙ‹Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ NaN Ø¨Ø¹Ø¯ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª.")
            if df.empty:
                logger.warning("âš ï¸ [Strategy] Ø£ØµØ¨Ø­ DataFrame ÙØ§Ø±ØºÙ‹Ø§ Ø¨Ø¹Ø¯ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª ÙˆØ­Ø°Ù NaN.")
                return pd.DataFrame()
            # logger.info(f"âœ… [Strategy] ØªÙ… Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ù„Ù€ DataFrame (Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: {len(df)})") # Can be noisy
            return df
        except Exception as e:
            logger.error(f"âŒ [Strategy] Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª: {e}", exc_info=True)
            return pd.DataFrame()

    def composite_buy_score(self, row):
        score = 0
        required_cols = ['ema5', 'ema8', 'ema21', 'ema34', 'ema50', 'rsi', 'close', 'lower_band', 'macd', 'macd_signal', 'macd_hist', 'kdj_j', 'kdj_k', 'kdj_d', 'adx', 'BullishSignal']
        if any(col not in row or pd.isna(row[col]) for col in required_cols):
            return 0
        try:
            if row['ema5'] > row['ema8'] > row['ema21'] > row['ema34'] > row['ema50']:
                score += 1.5
            if row['rsi'] < 40:
                score += 1
            if row['close'] > row['lower_band'] and ((row['close'] - row['lower_band']) / row['close'] < 0.02):
                score += 1
            if row['macd'] > row['macd_signal'] and row['macd_hist'] > 0:
                score += 1
            if row['kdj_j'] > row['kdj_k'] and row['kdj_k'] > row['kdj_d'] and row['kdj_j'] < 80:
                score += 1
            if row['adx'] > 20:
                score += 0.5
            if row['BullishSignal'] == 100:
                score += 1.5
        except TypeError as e:
             logger.error(f"âŒ [Strategy] Ø®Ø·Ø£ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø­Ø³Ø§Ø¨ composite_buy_score: {e}. Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙ: {row.to_dict()}")
             return 0
        except Exception as e:
             logger.error(f"âŒ [Strategy] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ composite_buy_score: {e}", exc_info=True)
             return 0
        return score

    def populate_buy_trend(self, df: pd.DataFrame) -> pd.DataFrame:
        required_score = 4.0
        required_cols = ['ema5', 'rsi', 'lower_band', 'macd', 'kdj_j', 'adx', 'BullishSignal'] # Simplified check
        if df.empty or not all(col in df.columns for col in required_cols):
             logger.warning("âš ï¸ [Strategy] DataFrame ÙŠÙØªÙ‚Ø¯ Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ø­Ø³Ø§Ø¨ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø´Ø±Ø§Ø¡.")
             df['buy_score'] = 0
             df['buy'] = 0
             return df
        # Make sure to calculate score only on rows without NaNs in relevant columns
        df['buy_score'] = df.apply(lambda row: self.composite_buy_score(row) if not row[required_cols].isnull().any() else 0, axis=1)
        df['buy'] = np.where(df['buy_score'] >= required_score, 1, 0)
        buy_signals_count = df['buy'].sum()
        if buy_signals_count > 0:
             logger.info(f"âœ… [Strategy] ØªÙ… ØªØ­Ø¯ÙŠØ¯ {buy_signals_count} Ø¥Ø´Ø§Ø±Ø©/Ø¥Ø´Ø§Ø±Ø§Øª Ø´Ø±Ø§Ø¡ Ù…Ø­ØªÙ…Ù„Ø© (Ø§Ù„Ø¯Ø±Ø¬Ø© >= {required_score}).")
        return df

# ---------------------- *** Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø³Ø¹Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ *** ----------------------
def predict_price_with_linear_regression(df_input: pd.DataFrame, symbol: str):
    """
    ÙŠØªÙ†Ø¨Ø£ Ø¨Ø³Ø¹Ø± Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ ÙˆÙŠØ¹ÙŠØ¯ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ ÙˆØ¯Ø±Ø¬Ø© RÂ².

    Args:
        df_input (pd.DataFrame): DataFrame Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© (ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 'open', 'high', 'low', 'close', 'volume').
        symbol (str): Ø±Ù…Ø² Ø§Ù„Ø¹Ù…Ù„Ø© (Ù„Ù„ØªØ³Ø¬ÙŠÙ„).

    Returns:
        tuple: (predicted_price, r2_score) Ø£Ùˆ (None, None) Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤.
    """
    try:
        logger.debug(f"â„¹ï¸ [LR Predict] Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ Ù„Ù„Ø²ÙˆØ¬ {symbol}...")
        df = df_input.copy()

        # 1. Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¨Ø³ÙŠØ·Ø©: Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙŠÙˆÙ… Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„ØºØ¯
        features = ['open', 'high', 'low', 'close', 'volume']
        if not all(f in df.columns for f in features):
            logger.warning(f"âš ï¸ [LR Predict] DataFrame Ù„Ù„Ø²ÙˆØ¬ {symbol} ÙŠÙØªÙ‚Ø¯ Ù„Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©: {features}")
            return None, None

        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ NaN ÙÙŠ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        df = df.dropna(subset=features)
        if df.empty:
            logger.warning(f"âš ï¸ [LR Predict] DataFrame Ù„Ù„Ø²ÙˆØ¬ {symbol} ÙØ§Ø±Øº Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© NaN ÙÙŠ Ø§Ù„Ù…ÙŠØ²Ø§Øª.")
            return None, None

        X = df[features]
        # Ø§Ù„Ù‡Ø¯Ù Ù‡Ùˆ Ø³Ø¹Ø± Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø´Ù…Ø¹Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©
        y = df['close'].shift(-1)

        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙ Ø§Ù„Ø£Ø®ÙŠØ± Ù…Ù† X Ùˆ y Ù„Ø£Ù†Ù‡ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù‡Ø¯Ù Ù„Ù„ØµÙ Ø§Ù„Ø£Ø®ÙŠØ±
        X = X[:-1]
        y = y[:-1]

        # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ NaN ÙÙŠ y (Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ÙØ§ØµÙ„ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª)
        combined = pd.concat([X, y.rename('Target')], axis=1).dropna()
        if combined.empty:
            logger.warning(f"âš ï¸ [LR Predict] Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ·Ø§Ø¨Ù‚Ø© Ø¨ÙŠÙ† Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙˆØ§Ù„Ù‡Ø¯Ù Ù„Ù„Ø²ÙˆØ¬ {symbol} Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© NaN.")
            return None, None

        X = combined[features]
        y = combined['Target']

        # 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„ØªÙ‚Ø³ÙŠÙ…
        if len(X) < 10: # Ø­Ø¯ Ø£Ø¯Ù†Ù‰ Ø¨Ø³ÙŠØ·
            logger.warning(f"âš ï¸ [LR Predict] Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© ({len(X)} ØµÙ) Ù„ØªØ¯Ø±ÙŠØ¨/Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ Ù„Ù„Ø²ÙˆØ¬ {symbol}.")
            return None, None

        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø­Ø¯Ø« Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…ÙŠØ²Ø§Øª Ù„Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (Ø¢Ø®Ø± ØµÙ ÙÙŠ df *Ø§Ù„Ø£ØµÙ„ÙŠ* Ù‚Ø¨Ù„ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙ Ø§Ù„Ø£Ø®ÙŠØ± Ù„Ù€ y)
        latest_features = df[features].iloc[-1:].copy()
        if latest_features.isnull().values.any():
             logger.warning(f"âš ï¸ [LR Predict] Ø£Ø­Ø¯Ø« Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù„Ù„Ø²ÙˆØ¬ {symbol} ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ NaN. Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„ØªÙ†Ø¨Ø¤ ØºÙŠØ± Ø¯Ù‚ÙŠÙ‚.")
             # ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ Ù‡Ù†Ø§ØŒ Ù…Ø«Ù„ Ø§Ù„Ù…Ù„Ø¡ Ø¨Ø§Ù„Ù…ØªÙˆØ³Ø·
             # latest_features = latest_features.fillna(X.mean()) # Ù…Ø«Ø§Ù„
             return None, None # Ø£Ùˆ Ø§Ù„ÙØ´Ù„ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø£Ø®ÙŠØ±Ø© ØºÙŠØ± ÙƒØ§Ù…Ù„Ø©

        # 3. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù…Ù‡Ù…: shuffle=False Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

        if len(X_train) == 0 or len(X_test) == 0:
            logger.warning(f"âš ï¸ [LR Predict] ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø¯Ù‰ Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© ÙØ§Ø±ØºØ© Ù„Ù„Ø²ÙˆØ¬ {symbol}.")
            return None, None

        # 4. ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        model = LinearRegression()
        model.fit(X_train, y_train)

        # 5. ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
        y_pred_test = model.predict(X_test)
        r2 = r2_score(y_test, y_pred_test)
        # mae = mean_absolute_error(y_test, y_pred_test) # ÙŠÙ…ÙƒÙ† Ø­Ø³Ø§Ø¨Ù‡Ø§ Ø£ÙŠØ¶Ù‹Ø§ Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª
        logger.info(f"âœ… [LR Predict] ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ Ù„Ù„Ø²ÙˆØ¬ {symbol}: RÂ² = {r2:.4f}")

        # 6. Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø­Ø¯Ø« Ø§Ù„Ù…ÙŠØ²Ø§Øª
        predicted_price = model.predict(latest_features)[0]

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù…Ø¹Ù‚ÙˆÙ„ (Ù„ÙŠØ³ Ø³Ø§Ù„Ø¨Ù‹Ø§ Ø£Ùˆ ØµÙØ±Ù‹Ø§)
        if predicted_price <= 0:
            logger.warning(f"âš ï¸ [LR Predict] Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ ØºÙŠØ± ØµØ§Ù„Ø­ ({predicted_price:.8f}) Ù„Ù„Ø²ÙˆØ¬ {symbol}.")
            return None, r2 # Ù‚Ø¯ Ù†Ø¹ÙŠØ¯ R2 Ø­ØªÙ‰ Ù„Ùˆ ÙØ´Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤ Ù„Ø³Ø¨Ø¨ Ù…Ø§

        logger.info(f"âœ… [LR Predict] Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ø¨Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ Ù„Ù„Ø²ÙˆØ¬ {symbol}: {predicted_price:.8f}")
        return float(f"{predicted_price:.8f}"), float(f"{r2:.4f}")

    except Exception as e:
        logger.error(f"âŒ [LR Predict] Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ Ù„Ù„Ø²ÙˆØ¬ {symbol}: {e}", exc_info=True)
        return None, None

# ---------------------- Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø© (GradientBoosting - Kept for reference) ----------------------
# (Ø¯Ø§Ù„Ø© improved_predict_future_price ÙƒÙ…Ø§ Ù‡ÙŠ - ÙŠÙ…ÙƒÙ† Ø¥Ø²Ø§Ù„ØªÙ‡Ø§ Ø¥Ø°Ø§ ÙƒÙ†Øª Ø³ØªØ¹ØªÙ…Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ)
# ... (Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© Ù…ÙˆØ¬ÙˆØ¯ Ù‡Ù†Ø§) ...
def improved_predict_future_price(symbol, interval='2h', days=30):
    try:
        df = fetch_historical_data(symbol, interval, days)
        if df is None or len(df) < 50: return None
        df['ema_fast'] = calculate_ema(df['close'], 10)
        df['ema_slow'] = calculate_ema(df['close'], 30)
        df['rsi'] = calculate_rsi_indicator(df)
        df = df.dropna()
        if len(df) < 2: return None
        features = ['ema_fast', 'ema_slow', 'rsi']
        if not all(f in df.columns for f in features): return None
        X = df[features].iloc[:-1].values
        y = df['close'].iloc[1:].values
        if len(X) == 0: return None
        # Make sure scikit-learn is installed if using this
        try:
            from sklearn.ensemble import GradientBoostingRegressor
        except ImportError:
            logger.error("âŒ [Price Prediction GBR] Ù…ÙƒØªØ¨Ø© scikit-learn ØºÙŠØ± Ù…Ø«Ø¨ØªØ©. Ø§Ù„ØªÙ†Ø¨Ø¤ GBR ØºÙŠØ± Ù…ØªØ§Ø­.")
            return None

        model = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42, learning_rate=0.1)
        model.fit(X, y)
        last_features = df[features].iloc[-1].values.reshape(1, -1)
        predicted_price = model.predict(last_features)[0]
        if predicted_price <= 0: return None
        logger.info(f"âœ… [Price Prediction GBR] Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù„Ù„Ø²ÙˆØ¬ {symbol} ({interval}, {days} ÙŠÙˆÙ…): {predicted_price:.8f}")
        return predicted_price
    except Exception as e:
        logger.error(f"âŒ [Price Prediction GBR] Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø³Ø¹Ø± Ù„Ù„Ø²ÙˆØ¬ {symbol}: {e}")
        return None


# ---------------------- Ø¯Ø§Ù„Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù†Ø© ÙˆØ§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ ----------------------
def generate_signal_using_freqtrade_strategy(df_input, symbol):
    if df_input is None or df_input.empty:
        logger.warning(f"âš ï¸ [Signal Gen] ØªÙ… ØªÙˆÙÙŠØ± DataFrame ÙØ§Ø±Øº Ù„Ù„Ø²ÙˆØ¬ {symbol}.")
        return None
    if len(df_input) < 50:
         logger.info(f"â„¹ï¸ [Signal Gen] Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© ({len(df_input)} Ø´Ù…Ø¹Ø©) Ù„Ù„Ø²ÙˆØ¬ {symbol} Ø¹Ù„Ù‰ ÙØ±ÙŠÙ… {SIGNAL_GENERATION_TIMEFRAME}.")
         return None

    # 1. ØªØ·Ø¨ÙŠÙ‚ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Freqtrade
    strategy = FreqtradeStrategy()
    df_processed = strategy.populate_indicators(df_input.copy())
    if df_processed.empty:
        logger.warning(f"âš ï¸ [Signal Gen] DataFrame ÙØ§Ø±Øº Ø¨Ø¹Ø¯ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ù„Ù„Ø²ÙˆØ¬ {symbol}.")
        return None

    df_with_signals = strategy.populate_buy_trend(df_processed)

    # 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¥Ø´Ø§Ø±Ø© Ø´Ø±Ø§Ø¡ Ù…Ù† Freqtrade
    if df_with_signals.empty or df_with_signals['buy'].iloc[-1] != 1:
        return None # Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø´Ø§Ø±Ø© Ø´Ø±Ø§Ø¡ Ù…Ù† Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©

    # 3. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    last_signal_row = df_with_signals.iloc[-1]
    current_price = last_signal_row['close']
    current_atr = last_signal_row.get('atr', None) # Ø§Ø³ØªØ®Ø¯Ø§Ù… .get Ù„Ù„ØªØ­Ù‚Ù‚

    if pd.isna(current_price) or pd.isna(current_atr) or current_atr is None or current_atr <= 0 or current_price <= 0:
        logger.warning(f"âš ï¸ [Signal Gen] Ø³Ø¹Ø± ({current_price}) Ø£Ùˆ ATR ({current_atr}) ØºÙŠØ± ØµØ§Ù„Ø­ ÙÙŠ ØµÙ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù„Ù„Ø²ÙˆØ¬ {symbol}.")
        return None

    # 4. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù‡Ø¯Ù ÙˆÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠ
    initial_target = current_price + (ENTRY_ATR_MULTIPLIER * current_atr)
    initial_stop_loss = current_price - (ENTRY_ATR_MULTIPLIER * current_atr)
    if initial_stop_loss <= 0:
        min_sl_price = current_price * 0.95
        initial_stop_loss = max(min_sl_price, 1e-9)
        logger.warning(f"âš ï¸ [Signal Gen] ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠ Ù„Ù„Ø²ÙˆØ¬ {symbol} ÙƒØ§Ù† ØºÙŠØ± Ù…ÙˆØ¬Ø¨. ØªÙ… ØªØ¹Ø¯ÙŠÙ„Ù‡ Ø¥Ù„Ù‰: {initial_stop_loss:.8f}")

    profit_margin_pct = ((initial_target / current_price) - 1) * 100 if current_price > 0 else 0
    if profit_margin_pct < MIN_PROFIT_MARGIN_PCT:
        logger.info(f"â„¹ï¸ [Signal Gen] ØªÙ… Ø±ÙØ¶ Ø¥Ø´Ø§Ø±Ø© {symbol}. Ù‡Ø§Ù…Ø´ Ø§Ù„Ø±Ø¨Ø­ ({profit_margin_pct:.2f}%) Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ ({MIN_PROFIT_MARGIN_PCT:.1f}%).")
        return None

    buy_score = last_signal_row.get('buy_score', 0)

    # 5. *** Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ ***
    # Ù†Ù…Ø±Ø± DataFrame *Ø§Ù„Ø£ØµÙ„ÙŠ* (df_input) Ù„Ø£Ù†Ù‡ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù„Ø§Ø²Ù…Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨
    predicted_price_lr, r2_score_lr = predict_price_with_linear_regression(df_input, symbol)
    # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø­Ø§Ù„Ø© ÙØ´Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤
    if predicted_price_lr is None:
        logger.warning(f"âš ï¸ [Signal Gen] ÙØ´Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ Ù„Ù„Ø²ÙˆØ¬ {symbol}. Ø³ÙŠØªÙ… ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù‚ÙŠÙ… Ø¥Ù„Ù‰ None.")
        predicted_price_lr = None
        r2_score_lr = None

    # 6. ØªØ¬Ù…ÙŠØ¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    signal = {
        'symbol': symbol,
        'entry_price': float(f"{current_price:.8f}"),
        'initial_target': float(f"{initial_target:.8f}"),
        'initial_stop_loss': float(f"{initial_stop_loss:.8f}"),
        'current_target': float(f"{initial_target:.8f}"),
        'current_stop_loss': float(f"{initial_stop_loss:.8f}"),
        'strategy': 'freqtrade_improved_atr',
        'indicators': {
            'rsi': round(last_signal_row['rsi'], 2) if 'rsi' in last_signal_row and pd.notna(last_signal_row['rsi']) else None,
            'macd_hist': round(last_signal_row['macd_hist'], 5) if 'macd_hist' in last_signal_row and pd.notna(last_signal_row['macd_hist']) else None,
            'adx': round(last_signal_row['adx'], 2) if 'adx' in last_signal_row and pd.notna(last_signal_row['adx']) else None,
            'atr': round(current_atr, 8),
            'buy_score': round(buy_score, 2)
        },
        'r2_score': round(buy_score, 2), # R2_score Ù…Ù† Freqtrade (buy_score)
        'trade_value': TRADE_VALUE,
        'predicted_price_lr': predicted_price_lr, # *** NEW
        'r2_score_lr': r2_score_lr               # *** NEW
    }

    logger.info(f"âœ… [Signal Gen] ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø¥Ø´Ø§Ø±Ø© Ø´Ø±Ø§Ø¡ Ù„Ù„Ø²ÙˆØ¬ {symbol} Ø¹Ù†Ø¯ Ø³Ø¹Ø± {current_price:.8f} (Ø¯Ø±Ø¬Ø© Freq: {buy_score:.2f}).")
    if predicted_price_lr is not None:
        logger.info(f"   [Signal Gen] ØªÙ†Ø¨Ø¤ LR: Ø§Ù„Ø³Ø¹Ø± = {predicted_price_lr:.8f}, RÂ² = {r2_score_lr if r2_score_lr is not None else 'N/A'}")

    return signal

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ ØªØ·Ø¨ÙŠÙ‚ Flask ----------------------
app = Flask(__name__)

@app.route('/')
def home():
    # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ù†Ø³Ø®Ø© Ø§Ù„ÙƒÙˆØ¯ Ø£Ùˆ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ø®Ø±Ù‰ Ù‡Ù†Ø§
    version = "4.4 (Hazem Mod + LR)"
    return f"ğŸš€ Ø¨ÙˆØª ØªÙˆØµÙŠØ§Øª Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ø¥ØµØ¯Ø§Ø± {version} - Ø®Ø¯Ù…Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª ØªØ¹Ù…Ù„. {datetime.utcnow().isoformat()}Z", 200

# (Ø¯Ø§Ù„Ø© webhook ÙƒÙ…Ø§ Ù‡ÙŠ)
@app.route('/webhook', methods=['POST'])
def webhook():
    try:
        update = request.get_json()
        if not update:
            logger.warning("âš ï¸ [Webhook] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… ØªØ­Ø¯ÙŠØ« ÙØ§Ø±Øº.")
            return '', 200
        logger.debug(f"ğŸ”” [Webhook] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… ØªØ­Ø¯ÙŠØ«: {json.dumps(update, indent=2)}")
        if "callback_query" in update:
            callback_query = update["callback_query"]
            data = callback_query.get("data")
            query_id = callback_query.get("id")
            message = callback_query.get("message")
            chat_info = message.get("chat", {}) if message else {}
            chat_id_callback = chat_info.get("id")
            user_info = callback_query.get("from", {})
            user_id = user_info.get("id")
            username = user_info.get("username", "N/A")
            if not chat_id_callback or not query_id:
                 logger.error(f"âŒ [Webhook] chat_id ({chat_id_callback}) Ø£Ùˆ query_id ({query_id}) Ù…ÙÙ‚ÙˆØ¯ ÙÙŠ callback_query.")
                 return 'Bad Request', 400
            answer_url = f"https://api.telegram.org/bot{telegram_token}/answerCallbackQuery"
            try:
                 requests.post(answer_url, json={"callback_query_id": query_id}, timeout=5)
            except Exception as ans_err:
                 logger.error(f"âŒ [Webhook] ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø±Ø¯ Ø¹Ù„Ù‰ Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ø±Ø¯ {query_id}: {ans_err}")
            logger.info(f"â„¹ï¸ [Webhook] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø±Ø¯ '{data}' Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… @{username} (ID: {user_id}) ÙÙŠ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© {chat_id_callback}.")
            if data == "get_report":
                Thread(target=send_report, args=(chat_id_callback,), daemon=True).start()
            else:
                 logger.warning(f"âš ï¸ [Webhook] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø±Ø¯ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©: {data}")
            return '', 200
        elif "message" in update and "text" in update["message"]:
             message = update["message"]
             chat_info = message.get("chat", {})
             chat_id_msg = chat_info.get("id")
             text = message.get("text", "").strip()
             user_info = message.get("from", {})
             user_id = user_info.get("id")
             username = user_info.get("username", "N/A")
             command = text.lower()
             if command == '/report' or command == '/stats' or command == '/ØªÙ‚Ø±ÙŠØ±':
                  logger.info(f"â„¹ï¸ [Webhook] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø§Ù„Ø£Ù…Ø± '{text}' Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… @{username} (ID: {user_id}) ÙÙŠ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© {chat_id_msg}.")
                  Thread(target=send_report, args=(chat_id_msg,), daemon=True).start()
                  return '', 200
             elif command == '/status' or command == '/Ø§Ù„Ø­Ø§Ù„Ø©':
                 logger.info(f"â„¹ï¸ [Webhook] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø§Ù„Ø£Ù…Ø± '{text}' Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… @{username} (ID: {user_id}) ÙÙŠ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© {chat_id_msg}.")
                 ws_status = 'Ù†Ø¹Ù…' if websocket_thread and websocket_thread.is_alive() else 'Ù„Ø§'
                 tracker_status = 'Ù†Ø¹Ù…' if tracker_thread and tracker_thread.is_alive() else 'Ù„Ø§'
                 scheduler_status = 'Ù†Ø¹Ù…' if scheduler and scheduler.running else 'Ù„Ø§'
                 status_msg = f"âœ… **Ø­Ø§Ù„Ø© Ø§Ù„Ø¨ÙˆØª** âœ…\n- Ø§ØªØµØ§Ù„ WebSocket: {ws_status}\n- Ø®Ø¯Ù…Ø© Ø§Ù„ØªØªØ¨Ø¹ Ù†Ø´Ø·Ø©: {tracker_status}\n- Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„ Ù†Ø´Ø·: {scheduler_status}"
                 send_telegram_update(status_msg, chat_id_override=chat_id_msg)
                 return '', 200
    except json.JSONDecodeError:
        logger.error("âŒ [Webhook] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… JSON ØºÙŠØ± ØµØ§Ù„Ø­.")
        return 'Invalid JSON', 400
    except Exception as e:
        logger.error(f"âŒ [Webhook] Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØ­Ø¯ÙŠØ«: {e}", exc_info=True)
        return 'Internal Server Error', 500
    return '', 200

# (Ø¯Ø§Ù„Ø© set_telegram_webhook ÙƒÙ…Ø§ Ù‡ÙŠ)
def set_telegram_webhook():
    render_service_name = os.environ.get("RENDER_SERVICE_NAME")
    if not render_service_name:
        webhook_base_url = config('WEBHOOK_BASE_URL', default=None)
        if not webhook_base_url:
             logger.warning("âš ï¸ [Webhook] Ù„Ù… ÙŠØªÙ… ØªØ¹ÙŠÙŠÙ† RENDER_SERVICE_NAME Ø£Ùˆ WEBHOOK_BASE_URL.")
             try:
                 get_wh_url = f"https://api.telegram.org/bot{telegram_token}/getWebhookInfo"
                 resp = requests.get(get_wh_url, timeout=10)
                 wh_info = resp.json()
                 if wh_info.get("ok") and wh_info.get("result",{}).get("url"):
                     logger.info(f"â„¹ï¸ [Webhook] ÙŠØ¨Ø¯Ùˆ Ø£Ù† Webhook Ù…Ø¹ÙŠÙ† Ø¨Ø§Ù„ÙØ¹Ù„ Ø¥Ù„Ù‰: {wh_info['result']['url']}")
                     return
                 else:
                     logger.warning("âš ï¸ [Webhook] Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† ØªØ£ÙƒÙŠØ¯ Ø¥Ø¹Ø¯Ø§Ø¯ webhook Ø§Ù„Ø­Ø§Ù„ÙŠ.")
             except Exception as e:
                 logger.error(f"âŒ [Webhook] Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† webhook Ø§Ù„Ø­Ø§Ù„ÙŠ: {e}")
             return
        webhook_url = f"{webhook_base_url.rstrip('/')}/webhook"
    else:
         webhook_url = f"https://{render_service_name}.onrender.com/webhook"
    set_url = f"https://api.telegram.org/bot{telegram_token}/setWebhook"
    params = {'url': webhook_url}
    try:
        response = requests.get(set_url, params=params, timeout=15)
        response.raise_for_status()
        res_json = response.json()
        if res_json.get("ok"):
            logger.info(f"âœ… [Webhook] ØªÙ… ØªØ¹ÙŠÙŠÙ† webhook ØªÙ„ÙŠØ¬Ø±Ø§Ù… Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù„Ù‰: {webhook_url}")
            logger.info(f"â„¹ï¸ [Webhook] Ø±Ø¯ ØªÙ„ÙŠØ¬Ø±Ø§Ù…: {res_json.get('description')}")
        else:
            logger.error(f"âŒ [Webhook] ÙØ´Ù„ ÙÙŠ ØªØ¹ÙŠÙŠÙ† webhook: {res_json}")
    except requests.exceptions.RequestException as e:
        logger.error(f"âŒ [Webhook] Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø£Ø«Ù†Ø§Ø¡ Ø·Ù„Ø¨ Ø¥Ø¹Ø¯Ø§Ø¯ webhook: {e}")
    except Exception as e:
        logger.error(f"âŒ [Webhook] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ø¹Ø¯Ø§Ø¯ webhook: {e}")

# ---------------------- ÙˆØ¸Ø§Ø¦Ù ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ----------------------
# (Ø¯ÙˆØ§Ù„ get_crypto_symbols, fetch_historical_data, fetch_recent_volume ÙƒÙ…Ø§ Ù‡ÙŠ)
# ... (Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø¯ÙˆØ§Ù„ Ù…ÙˆØ¬ÙˆØ¯ Ù‡Ù†Ø§) ...
def get_crypto_symbols(filename='crypto_list.txt'):
    symbols = []
    try:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        file_path = os.path.join(script_dir, filename)
        if not os.path.exists(file_path):
            logger.error(f"âŒ [Data] Ù…Ù„Ù Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ù…ÙˆØ² '{filename}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø±: {file_path}")
            alt_path = os.path.abspath(filename)
            if os.path.exists(alt_path):
                logger.warning(f"âš ï¸ [Data] Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ù„Ù Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø­Ø§Ù„ÙŠ: {alt_path}")
                file_path = alt_path
            else:
                return []
        with open(file_path, 'r', encoding='utf-8') as f:
            symbols = [f"{line.strip().upper()}USDT" for line in f if line.strip() and not line.startswith('#')]
        logger.info(f"âœ… [Data] ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(symbols)} Ø±Ù…Ø²Ù‹Ø§ Ù…Ù† '{os.path.basename(file_path)}'.")
        return symbols
    except Exception as e:
        logger.error(f"âŒ [Data] Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ø±Ù…ÙˆØ² '{filename}': {e}")
        return []

def fetch_historical_data(symbol, interval='1h', days=10):
    try:
        start_str = f"{days} day ago UTC"
        # Ensure interval is valid for binance client
        valid_intervals = [
            Client.KLINE_INTERVAL_1MINUTE, Client.KLINE_INTERVAL_3MINUTE, Client.KLINE_INTERVAL_5MINUTE,
            Client.KLINE_INTERVAL_15MINUTE, Client.KLINE_INTERVAL_30MINUTE, Client.KLINE_INTERVAL_1HOUR,
            Client.KLINE_INTERVAL_2HOUR, Client.KLINE_INTERVAL_4HOUR, Client.KLINE_INTERVAL_6HOUR,
            Client.KLINE_INTERVAL_8HOUR, Client.KLINE_INTERVAL_12HOUR, Client.KLINE_INTERVAL_1DAY,
            Client.KLINE_INTERVAL_3DAY, Client.KLINE_INTERVAL_1WEEK, Client.KLINE_INTERVAL_1MONTH
        ]
        if interval not in valid_intervals:
            # Attempt to map common intervals if possible, otherwise default or error
            interval_map = {'1h': Client.KLINE_INTERVAL_1HOUR, '15m': Client.KLINE_INTERVAL_15MINUTE, '2h': Client.KLINE_INTERVAL_2HOUR, '4h': Client.KLINE_INTERVAL_4HOUR, '1d': Client.KLINE_INTERVAL_1DAY}
            mapped_interval = interval_map.get(interval.lower())
            if mapped_interval:
                interval = mapped_interval
                logger.debug(f"â„¹ï¸ [Data] ØªÙ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙØ§ØµÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ Ø¥Ù„Ù‰ {interval} Ù„Ù„Ø²ÙˆØ¬ {symbol}.")
            else:
                logger.error(f"âŒ [Data] ÙØ§ØµÙ„ Ø²Ù…Ù†ÙŠ ØºÙŠØ± ØµØ§Ù„Ø­ '{interval}' Ù„Ù„Ø²ÙˆØ¬ {symbol}. Ø§Ø³ØªØ®Ø¯Ø§Ù… '1h' ÙƒØ§ÙØªØ±Ø§Ø¶ÙŠ.")
                interval = Client.KLINE_INTERVAL_1HOUR

        klines = client.get_historical_klines(symbol, interval, start_str)

        if not klines:
            logger.warning(f"âš ï¸ [Data] Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„Ù„Ø²ÙˆØ¬ {symbol} ({interval}, {days} ÙŠÙˆÙ…).")
            return None
        df = pd.DataFrame(klines, columns=[
            'timestamp', 'open', 'high', 'low', 'close', 'volume',
            'close_time', 'quote_volume', 'trades',
            'taker_buy_base', 'taker_buy_quote', 'ignore'
        ])
        # Convert essential columns to numeric, coercing errors
        for col in ['open', 'high', 'low', 'close', 'volume', 'quote_volume']:
            df[col] = pd.to_numeric(df[col], errors='coerce')

        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')

        # Drop rows where essential price data is missing *after* conversion
        initial_len = len(df)
        df.dropna(subset=['open', 'high', 'low', 'close'], inplace=True)
        if len(df) < initial_len:
             logger.debug(f"â„¹ï¸ [Data] ØªÙ… Ø­Ø°Ù {initial_len - len(df)} ØµÙÙ‹Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø³Ø¹Ø§Ø± NaN Ù„Ù„Ø²ÙˆØ¬ {symbol}.")

        if df.empty:
             logger.warning(f"âš ï¸ [Data] DataFrame Ù„Ù„Ø²ÙˆØ¬ {symbol} Ø£ØµØ¨Ø­ ÙØ§Ø±ØºÙ‹Ø§ Ø¨Ø¹Ø¯ Ù…Ø¹Ø§Ù„Ø¬Ø© NaN.")
             return None
        # Return only the necessary columns
        return df[['timestamp', 'open', 'high', 'low', 'close', 'volume']].reset_index(drop=True)
    except Exception as e:
        logger.error(f"âŒ [Data] Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø²ÙˆØ¬ {symbol} ({interval}, {days} ÙŠÙˆÙ…): {e}")
        return None

def fetch_recent_volume(symbol):
    try:
        # Get last 15 minutes of volume using 1m candles
        klines = client.get_klines(symbol=symbol, interval=Client.KLINE_INTERVAL_1MINUTE, limit=15)
        if not klines:
             logger.warning(f"âš ï¸ [Data] Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø´Ù…ÙˆØ¹ 1m Ù„Ù„Ø²ÙˆØ¬ {symbol} Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ø£Ø®ÙŠØ±.")
             return 0.0
        # Calculate quote asset volume (volume in USDT)
        volume = sum(float(k[7]) for k in klines if len(k) > 7 and k[7]) # k[7] is quote asset volume
        return volume
    except Exception as e:
        logger.error(f"âŒ [Data] Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ø£Ø®ÙŠØ± Ù„Ù„Ø²ÙˆØ¬ {symbol}: {e}")
        return 0.0

# ---------------------- Ø¯Ù…Ø¬ Gemini API (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) ----------------------
# (Ø¯ÙˆØ§Ù„ Gemini ÙƒÙ…Ø§ Ù‡ÙŠ - ÙŠÙ…ÙƒÙ† Ø¥Ø²Ø§Ù„ØªÙ‡Ø§ Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…Ø·Ù„ÙˆØ¨Ø©)
# ... (Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø¯ÙˆØ§Ù„ Ù…ÙˆØ¬ÙˆØ¯ Ù‡Ù†Ø§) ...
def get_gemini_volume(pair):
    """ÙŠØ¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠÙƒØ± Ù…Ù† Gemini API Ù„Ù„Ø²ÙˆØ¬ Ø§Ù„Ù…Ø­Ø¯Ø¯."""
    try:
        url = f"https://api.gemini.com/v1/pubticker/{pair}"
        response = requests.get(url, timeout=10)
        response.raise_for_status() # Check for HTTP errors
        data = response.json()
        # Gemini volume is reported in the base currency (e.g., BTC for BTCUSD)
        # We need to get the volume in the quote currency (USD)
        volume_base = data.get("volume", {}).get(pair[:3].upper()) # e.g., get 'BTC' volume
        last_price = data.get("last")

        if volume_base is None or last_price is None:
            logger.warning(f"âš ï¸ [Gemini] Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø¬Ù… Ø£Ùˆ Ø§Ù„Ø³Ø¹Ø± Ù…ÙÙ‚ÙˆØ¯Ø© Ù„Ù„Ø²ÙˆØ¬ {pair}. Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©: {data}")
            return 0.0

        volume_quote = float(volume_base) * float(last_price)
        logger.info(f"âœ… [Gemini] Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ (Quote) Ù„Ù„Ø²ÙˆØ¬ {pair}: {volume_quote:.2f}")
        return volume_quote
    except requests.exceptions.RequestException as e:
        logger.error(f"âŒ [Gemini] Ø®Ø·Ø£ Ø´Ø¨ÙƒØ©/API ÙÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠÙƒØ± Ù„Ù„Ø²ÙˆØ¬ {pair}: {e}")
        return 0.0
    except Exception as e:
        logger.error(f"âŒ [Gemini] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠÙƒØ± Ù„Ù„Ø²ÙˆØ¬ {pair}: {e}")
        return 0.0

def calculate_market_dominance():
    """ÙŠØ­Ø³Ø§Ø¨ Ù†Ø³Ø¨ Ø§Ù„Ø§Ø³ØªØ­ÙˆØ§Ø° Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª Gemini API Ù„Ù„Ø²ÙˆØ¬ÙŠÙ† BTCUSD Ùˆ ETHUSD."""
    # Note: Gemini uses pairs like 'btcusd', 'ethusd'
    btc_volume_usd = get_gemini_volume("btcusd")
    eth_volume_usd = get_gemini_volume("ethusd")
    total_volume = btc_volume_usd + eth_volume_usd

    if total_volume <= 0: # Use <= 0 for safety
         logger.warning("âš ï¸ [Gemini] Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ù„Ù„Ø²ÙˆØ¬ÙŠÙ† ØµÙØ± Ø£Ùˆ Ø³Ø§Ù„Ø¨ØŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨ Ø§Ù„Ø§Ø³ØªØ­ÙˆØ§Ø°.")
         return 0.0, 0.0 # Return default values

    btc_dominance = (btc_volume_usd / total_volume) * 100 if total_volume > 0 else 0
    eth_dominance = (eth_volume_usd / total_volume) * 100 if total_volume > 0 else 0

    logger.info(f"âœ… [Gemini] Ù†Ø³Ø¨ Ø§Ù„Ø§Ø³ØªØ­ÙˆØ§Ø° - BTC: {btc_dominance:.2f}%, ETH: {eth_dominance:.2f}%")
    return btc_dominance, eth_dominance

# ---------------------- *** Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø¹Ø¨Ø± Telegram (Ù…ÙØ­Ø¯ÙÙ‘Ø«) *** ----------------------
def send_telegram_alert(signal, volume, btc_dominance, eth_dominance, timeframe):
    try:
        entry_price = signal['entry_price']
        target_price = signal['initial_target']
        stop_loss_price = signal['initial_stop_loss']

        # --- Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ Ù…Ù† Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ ---
        predicted_price_lr = signal.get('predicted_price_lr')
        r2_score_lr = signal.get('r2_score_lr')
        # ----------------------------------------------------

        if entry_price <= 0:
             logger.error(f"âŒ [Telegram] Ø³Ø¹Ø± Ø§Ù„Ø¯Ø®ÙˆÙ„ ØºÙŠØ± ØµØ§Ù„Ø­ ({entry_price}) Ù„Ù„Ø²ÙˆØ¬ {signal['symbol']}. Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡.")
             return

        profit_pct = ((target_price / entry_price) - 1) * 100
        loss_pct = ((stop_loss_price / entry_price) - 1) * 100
        profit_usdt = TRADE_VALUE * (profit_pct / 100)
        loss_usdt = TRADE_VALUE * (loss_pct / 100)

        timestamp = (datetime.utcnow() + timedelta(hours=3)).strftime('%Y-%m-%d %H:%M') # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„ØªÙˆÙ‚ÙŠØª Ø¥Ù„Ù‰ +3
        fng_value, fng_label = get_fear_greed_index()
        safe_symbol = signal['symbol'].replace('_', '\\_').replace('*', '\\*').replace('[', '\\[').replace('`', '\\`')

        # --- Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø±Ø³Ø§Ù„Ø© ---
        message_lines = [
            f"ğŸš€ **hamza ØªÙˆØµÙŠØ© ØªØ¯Ø§ÙˆÙ„ Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ø¨ÙˆØª** ğŸš€",
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”",
            f"ğŸª™ **Ø§Ù„Ø²ÙˆØ¬:** `{safe_symbol}`",
            f"ğŸ“ˆ **Ø³Ø¹Ø± Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…Ù‚ØªØ±Ø­:** `${entry_price:.8f}`",
            f"ğŸ¯ **Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø£ÙˆÙ„ÙŠ:** `${target_price:.8f}` ({profit_pct:+.2f}% / {profit_usdt:+.2f} USDT)",
            f"ğŸ›‘ **ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠ:** `${stop_loss_price:.8f}` ({loss_pct:.2f}% / {loss_usdt:.2f} USDT)",
            f"â± **Ø§Ù„ÙØ±ÙŠÙ… Ø§Ù„Ø²Ù…Ù†ÙŠ Ù„Ù„Ø¥Ø´Ø§Ø±Ø©:** {timeframe}",
            f"ğŸ’§ **Ø§Ù„Ø³ÙŠÙˆÙ„Ø© (Ø¢Ø®Ø± 15Ø¯):** {volume:,.0f} USDT",
            f"ğŸ’° **Ù‚ÙŠÙ…Ø© Ø§Ù„ØµÙÙ‚Ø© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©:** ${TRADE_VALUE}",
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”",
            f"ğŸ” **ØªØ­Ù„ÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠ (Linear Regression):**"
        ]

        # --- Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ØªÙˆÙØ±Ø© ---
        if predicted_price_lr is not None:
            message_lines.append(f"   - Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ø§Ù„ØªØ§Ù„ÙŠ: `${predicted_price_lr:.8f}`")
        else:
            message_lines.append(f"   - Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ø§Ù„ØªØ§Ù„ÙŠ: `N/A`")

        if r2_score_lr is not None:
             # ØªÙØ³ÙŠØ± Ø¨Ø³ÙŠØ· Ù„Ù€ R-squared
            if r2_score_lr < 0: r2_interp = "(Ù†Ù…ÙˆØ°Ø¬ Ø³ÙŠØ¡)"
            elif r2_score_lr < 0.5: r2_interp = "(Ù‚Ø¯Ø±Ø© ØªÙØ³ÙŠØ±ÙŠØ© Ø¶Ø¹ÙŠÙØ©)"
            elif r2_score_lr < 0.8: r2_interp = "(Ù‚Ø¯Ø±Ø© ØªÙØ³ÙŠØ±ÙŠØ© Ù…Ù‚Ø¨ÙˆÙ„Ø©)"
            else: r2_interp = "(Ù‚Ø¯Ø±Ø© ØªÙØ³ÙŠØ±ÙŠØ© Ø¬ÙŠØ¯Ø©)"
            message_lines.append(f"   - Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (RÂ²): {r2_score_lr:.2%} {r2_interp}")
        else:
             message_lines.append(f"   - Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (RÂ²): `N/A`")
        # -------------------------------------------------------

        message_lines.extend([
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”",
            f"ğŸŒ **Ø¸Ø±ÙˆÙ Ø§Ù„Ø³ÙˆÙ‚:**",
            f"   - Ø³ÙŠØ·Ø±Ø© BTC: {btc_dominance:.2f}%",
            f"   - Ø³ÙŠØ·Ø±Ø© ETH: {eth_dominance:.2f}%",
            f"   - Ù…Ø¤Ø´Ø± Ø§Ù„Ø®ÙˆÙ/Ø§Ù„Ø¬Ø´Ø¹: {fng_value:.0f} ({fng_label})",
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”",
            f"â° {timestamp} (ØªÙˆÙ‚ÙŠØª +3)"
        ])

        message = "\n".join(message_lines)

        reply_markup = {
            "inline_keyboard": [
                [{"text": "ğŸ“Š Ø¹Ø±Ø¶ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡", "callback_data": "get_report"}]
            ]
        }
        send_telegram_message(chat_id, message, reply_markup=reply_markup)
        logger.info(f"âœ… [Telegram] ØªÙ… Ø¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡ Ø§Ù„ØªÙˆØµÙŠØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ø²ÙˆØ¬ {signal['symbol']} (Ù…Ø¹ ØªÙ†Ø¨Ø¤ LR).")

    except Exception as e:
        logger.error(f"âŒ [Telegram] ÙØ´Ù„ ÙÙŠ Ø¨Ù†Ø§Ø¡ Ø£Ùˆ Ø¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡ Ø§Ù„ØªÙˆØµÙŠØ© Ù„Ù„Ø²ÙˆØ¬ {signal['symbol']}: {e}", exc_info=True)

# (Ø¯ÙˆØ§Ù„ send_telegram_update, send_telegram_message ÙƒÙ…Ø§ Ù‡ÙŠ)
def send_telegram_update(message, chat_id_override=None):
    target_chat = chat_id_override if chat_id_override else chat_id
    try:
        reply_markup = {
            "inline_keyboard": [
                [{"text": "ğŸ“Š Ø¹Ø±Ø¶ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡", "callback_data": "get_report"}]
            ]
        }
        send_telegram_message(target_chat, message, reply_markup=reply_markup)
        logger.info(f"âœ… [Telegram] ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù„Ù‰ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© {target_chat}.")
    except Exception as e:
        logger.error(f"âŒ [Telegram] ÙØ´Ù„ ÙÙŠ Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø¥Ù„Ù‰ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© {target_chat}: {e}")

def send_telegram_message(chat_id_target, text, reply_markup=None, parse_mode='Markdown', disable_web_page_preview=True, timeout=15):
    url = f"https://api.telegram.org/bot{telegram_token}/sendMessage"
    payload = {
        'chat_id': chat_id_target,
        'text': text,
        'parse_mode': parse_mode,
        'disable_web_page_preview': disable_web_page_preview
    }
    if reply_markup:
        payload['reply_markup'] = json.dumps(reply_markup)
    try:
        response = requests.post(url, json=payload, timeout=timeout)
        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)
        res_json = response.json()
        if not res_json.get("ok"):
            logger.error(f"âŒ [Telegram] API Error: {res_json.get('description')} (Code: {res_json.get('error_code')}) when sending to {chat_id_target}")
        return res_json
    except requests.exceptions.Timeout:
         logger.error(f"âŒ [Telegram] Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø·Ù„Ø¨ Ø¹Ù†Ø¯ Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© {chat_id_target}.")
         # Optionally re-raise or return an indicator of failure
         return None # Or raise
    except requests.exceptions.RequestException as e:
        logger.error(f"âŒ [Telegram] Ø®Ø·Ø£ Ø´Ø¨ÙƒØ©/API Ø¹Ù†Ø¯ Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© {chat_id_target}: {e}")
        if e.response is not None:
            try:
                error_info = e.response.json()
                logger.error(f"âŒ [Telegram] ØªÙØ§ØµÙŠÙ„ Ø®Ø·Ø£ API: {error_info}")
            except json.JSONDecodeError:
                logger.error(f"âŒ [Telegram] Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø®Ø·Ø£ API Ù„ÙŠØ³Øª JSON: {e.response.text}")
        return None # Or raise
    except Exception as e:
        logger.error(f"âŒ [Telegram] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø¹Ù†Ø¯ Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© {chat_id_target}: {e}")
        return None # Or raise

# ---------------------- Ø¥Ø±Ø³Ø§Ù„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø´Ø§Ù…Ù„ ----------------------
# (Ø¯Ø§Ù„Ø© send_report ÙƒÙ…Ø§ Ù‡ÙŠ)
def send_report(target_chat_id):
    logger.info(f"â³ [Report] Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù„Ù„Ø¯Ø±Ø¯Ø´Ø©: {target_chat_id}")
    report_message = "âš ï¸ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡."
    try:
        check_db_connection() # Ensure connection is active
        cur.execute("SELECT COUNT(*) FROM signals WHERE closed_at IS NULL")
        active_count = cur.fetchone()[0]

        # Fetch necessary columns for closed trades calculation
        cur.execute("""
            SELECT achieved_target, hit_stop_loss, profitable_stop_loss, profit_percentage
            FROM signals WHERE closed_at IS NOT NULL
        """)
        closed_signals = cur.fetchall()
        total_closed_trades = len(closed_signals)

        if total_closed_trades == 0:
            report_message = f"ğŸ“Š **ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡**\n\nÙ„Ø§ ØªÙˆØ¬Ø¯ ØµÙÙ‚Ø§Øª Ù…ØºÙ„Ù‚Ø© Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†.\nâ³ **Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù†Ø´Ø·Ø© Ø­Ø§Ù„ÙŠØ§Ù‹:** {active_count}"
            send_telegram_update(report_message, chat_id_override=target_chat_id)
            logger.info("âœ… [Report] ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± (Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙÙ‚Ø§Øª Ù…ØºÙ„Ù‚Ø©).")
            return

        # Calculate metrics
        successful_target_hits = sum(1 for s in closed_signals if s[0] is True) # achieved_target
        profitable_sl_hits = sum(1 for s in closed_signals if s[1] is True and s[2] is True) # hit_stop_loss and profitable_stop_loss
        losing_sl_hits = sum(1 for s in closed_signals if s[1] is True and s[2] is False) # hit_stop_loss and not profitable_stop_loss
        # Note: Some trades might close without hitting target or stoploss if manually closed or error - these are excluded from win rate calculation here

        total_profit_usd = 0
        total_loss_usd = 0
        profit_percentages = []
        loss_percentages = []

        for signal in closed_signals:
            profit_pct = signal[3] # profit_percentage
            if profit_pct is not None:
                # Assume fixed TRADE_VALUE for calculation simplicity
                trade_result_usd = TRADE_VALUE * (profit_pct / 100)
                if trade_result_usd > 0:
                    total_profit_usd += trade_result_usd
                    profit_percentages.append(profit_pct)
                else:
                    total_loss_usd += trade_result_usd # This will be negative
                    loss_percentages.append(profit_pct)
            else:
                 logger.warning(f"âš ï¸ [Report] ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØªÙˆØµÙŠØ© Ù…ØºÙ„Ù‚Ø© Ø¨Ø¯ÙˆÙ† profit_percentage. ID not available here.")

        net_profit_usd = total_profit_usd + total_loss_usd # total_loss_usd is negative

        # Calculate Win Rate based on trades that hit target or were profitable stops
        total_wins = successful_target_hits + profitable_sl_hits
        # Base for win rate could be total closed trades, or only those hitting target/SL
        win_rate = (total_wins / total_closed_trades) * 100 if total_closed_trades > 0 else 0

        avg_profit_pct = np.mean(profit_percentages) if profit_percentages else 0
        avg_loss_pct = np.mean(loss_percentages) if loss_percentages else 0

        # Calculate Profit Factor safely
        profit_factor = abs(total_profit_usd / total_loss_usd) if total_loss_usd != 0 else float('inf') # Handle division by zero

        timestamp = (datetime.utcnow() + timedelta(hours=3)).strftime('%Y-%m-%d %H:%M') # Adjust timezone as needed

        # Format the report message
        report_message = (
            f"ğŸ“Š **Hamza ØªÙ‚Ø±ÙŠØ± Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¨ÙˆØª** ({timestamp} ØªÙˆÙ‚ÙŠØª +3)\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"**Ù…Ù„Ø®Øµ Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø© ({total_closed_trades}):**\n"
            f"  âœ… ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ù‡Ø¯Ù: {successful_target_hits}\n"
            f"  ğŸ“ˆ ÙˆÙ‚Ù Ø®Ø³Ø§Ø±Ø© Ø±Ø§Ø¨Ø­: {profitable_sl_hits}\n"
            f"  ğŸ“‰ ÙˆÙ‚Ù Ø®Ø³Ø§Ø±Ø© Ø®Ø§Ø³Ø±: {losing_sl_hits}\n"
            f"  ğŸ“Š Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø±Ø¨Ø­ (Win Rate): {win_rate:.2f}%\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"**Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø§Ù„ÙŠ (Ø¨Ù‚ÙŠÙ…Ø© ØµÙÙ‚Ø© ${TRADE_VALUE}):**\n" # Clarify assumption
            f"  ğŸ’° Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±Ø¨Ø­: +{total_profit_usd:.2f} USDT\n"
            f"  ğŸ’¸ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø®Ø³Ø§Ø±Ø©: {total_loss_usd:.2f} USDT\n"
            f"  ğŸ’µ **ØµØ§ÙÙŠ Ø§Ù„Ø±Ø¨Ø­/Ø§Ù„Ø®Ø³Ø§Ø±Ø©:** {net_profit_usd:+.2f} USDT\n"
            f"  ğŸ¯ Ù…ØªÙˆØ³Ø· Ø±Ø¨Ø­ Ø§Ù„ØµÙÙ‚Ø©: {avg_profit_pct:+.2f}%\n"
            f"  ğŸ›‘ Ù…ØªÙˆØ³Ø· Ø®Ø³Ø§Ø±Ø© Ø§Ù„ØµÙÙ‚Ø©: {avg_loss_pct:.2f}%\n"
            f"  âš–ï¸ Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø±Ø¨Ø­ (Profit Factor): {profit_factor:.2f if profit_factor != float('inf') else 'âˆ'}\n" # Display âˆ for infinite PF
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"â³ **Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù†Ø´Ø·Ø© Ø­Ø§Ù„ÙŠØ§Ù‹:** {active_count}"
        )

        send_telegram_update(report_message, chat_id_override=target_chat_id)
        logger.info(f"âœ… [Report] ØªÙ… Ø¥Ø±Ø³Ø§Ù„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù„Ù‰ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© {target_chat_id}.")

    except psycopg2.Error as db_err:
        logger.error(f"âŒ [Report] Ø®Ø·Ø£ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø«Ù†Ø§Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {db_err}")
        if conn and not conn.closed: conn.rollback() # Rollback on error
        report_message = f"âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø«Ù†Ø§Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±.\n`{db_err}`"
        try:
            # Send error message to the user who requested the report
            send_telegram_message(target_chat_id, report_message, parse_mode='Markdown')
        except Exception as send_err:
             logger.error(f"âŒ [Report] ÙØ´Ù„ ÙÙŠ Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø®Ø·Ø£ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {send_err}")
    except Exception as e:
        logger.error(f"âŒ [Report] ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø£Ùˆ Ø¥Ø±Ø³Ø§Ù„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡: {e}", exc_info=True)
        report_message = f"âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±.\n`{e}`"
        try:
            # Send general error message
            send_telegram_message(target_chat_id, report_message, parse_mode='Markdown')
        except Exception as send_err:
             logger.error(f"âŒ [Report] ÙØ´Ù„ ÙÙŠ Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ø¹Ø§Ù…Ø©: {send_err}")


# ---------------------- Ø®Ø¯Ù…Ø© ØªØªØ¨Ø¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª ÙˆØªØ­Ø¯ÙŠØ«Ù‡Ø§ ----------------------
# (Ø¯Ø§Ù„Ø© track_signals ÙƒÙ…Ø§ Ù‡ÙŠ - Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ØªÙ…Øª ÙÙŠ init_db Ùˆ analyze_market Ùˆ send_telegram_alert)
# ... (Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© Ù…ÙˆØ¬ÙˆØ¯ Ù‡Ù†Ø§) ...
def track_signals():
    logger.info(f"ğŸ”„ [Tracker] Ø¨Ø¯Ø¡ Ø®Ø¯Ù…Ø© ØªØªØ¨Ø¹ Ø§Ù„ØªÙˆØµÙŠØ§Øª (Ø§Ù„ÙØ±ÙŠÙ…: {SIGNAL_TRACKING_TIMEFRAME}, Ø¨ÙŠØ§Ù†Ø§Øª: {SIGNAL_TRACKING_LOOKBACK_DAYS} ÙŠÙˆÙ…)...")
    while True:
        try:
            check_db_connection() # Ensure DB connection is alive
            cur.execute("""
                SELECT id, symbol, entry_price, initial_stop_loss, current_target, current_stop_loss, is_trailing_active
                FROM signals
                WHERE closed_at IS NULL
            """)
            active_signals = cur.fetchall()

            if not active_signals:
                # logger.debug("[Tracker] No active signals to track.") # Reduce noise
                time.sleep(20) # Sleep longer if nothing to track
                continue

            # logger.info("==========================================") # Reduce noise
            logger.info(f"ğŸ” [Tracker] Ø¬Ø§Ø±ÙŠ ØªØªØ¨Ø¹ {len(active_signals)} ØªÙˆØµÙŠØ© Ù†Ø´Ø·Ø©...")

            for signal_data in active_signals:
                try:
                    signal_id, symbol, entry_price, initial_stop_loss, current_target, current_stop_loss, is_trailing_active = signal_data
                    current_price = None

                    # Get current price from WebSocket data
                    if symbol not in ticker_data or ticker_data[symbol].get('c') is None:
                        logger.warning(f"âš ï¸ [Tracker] Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø³Ø¹Ø± Ø­Ø§Ù„ÙŠØ© Ù…Ù† WebSocket Ù„Ù„Ø²ÙˆØ¬ {symbol} (ID: {signal_id}). ØªØ®Ø·ÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø¯ÙˆØ±Ø©.")
                        continue # Skip this signal for this cycle

                    price_str = ticker_data[symbol]['c']
                    if price_str is not None:
                         current_price = float(price_str)
                         if current_price <= 0:
                              logger.warning(f"âš ï¸ [Tracker] Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ Ø§Ù„Ù…Ø³ØªÙ„Ù… ØºÙŠØ± ØµØ§Ù„Ø­ ({current_price}) Ù„Ù„Ø²ÙˆØ¬ {symbol} (ID: {signal_id}). ØªØ®Ø·ÙŠ.")
                              current_price = None # Invalidate price
                    else:
                         logger.warning(f"âš ï¸ [Tracker] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ù‚ÙŠÙ…Ø© Ø³Ø¹Ø± None ('c') Ù„Ù„Ø²ÙˆØ¬ {symbol} (ID: {signal_id}). ØªØ®Ø·ÙŠ.")
                         current_price = None # Invalidate price

                except (ValueError, TypeError) as e:
                     logger.warning(f"âš ï¸ [Tracker] Ù‚ÙŠÙ…Ø© Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…Ø³ØªÙ„Ù…Ø© ({ticker_data.get(symbol,{}).get('c')}) ØºÙŠØ± Ø±Ù‚Ù…ÙŠØ© Ù„Ù„Ø²ÙˆØ¬ {symbol} (ID: {signal_id}): {e}. ØªØ®Ø·ÙŠ.")
                     current_price = None # Invalidate price
                except Exception as fetch_err:
                     logger.error(f"âŒ [Tracker] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø³Ø¹Ø± {symbol} (ID: {signal_id}): {fetch_err}")
                     continue # Skip this signal

                if current_price is None:
                     continue # Skip if price is invalid

                # Basic sanity checks for data from DB
                if entry_price is None or entry_price <= 0 or current_target is None or current_stop_loss is None:
                    logger.error(f"âŒ [Tracker] Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø±Ø¬Ø© Ù…ÙÙ‚ÙˆØ¯Ø© Ø£Ùˆ ØºÙŠØ± ØµØ§Ù„Ø­Ø© Ù…Ù† DB Ù„Ù„ØªÙˆØµÙŠØ© ID {signal_id} ({symbol}): Ø§Ù„Ø¯Ø®ÙˆÙ„={entry_price}, Ø§Ù„Ù‡Ø¯Ù={current_target}, Ø§Ù„ÙˆÙ‚Ù={current_stop_loss}.")
                    # Consider closing the signal with an error status here?
                    continue # Skip this signal for safety

                logger.info(f"  [Tracker] {symbol} (ID:{signal_id}) | Ø§Ù„Ø³Ø¹Ø±: {current_price:.8f} | Ø§Ù„Ø¯Ø®ÙˆÙ„: {entry_price:.8f} | Ø§Ù„Ù‡Ø¯Ù: {current_target:.8f} | Ø§Ù„ÙˆÙ‚Ù: {current_stop_loss:.8f} | Ù…ØªØ­Ø±Ùƒ: {is_trailing_active}")

                # Check for Target Hit
                if current_price >= current_target:
                    profit_pct = ((current_target / entry_price) - 1) * 100
                    profit_usdt = TRADE_VALUE * (profit_pct / 100)
                    safe_symbol = symbol.replace('_', '\\_').replace('*', '\\*').replace('[', '\\[').replace('`', '\\`')
                    msg = (f"âœ… **ØªÙ… ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ù‡Ø¯Ù!** âœ…\n"
                           f"ğŸ“ˆ Ø§Ù„Ø²ÙˆØ¬: `{safe_symbol}` (ID: {signal_id})\n"
                           f"ğŸ’° Ø£ØºÙ„Ù‚ Ø¹Ù†Ø¯: ${current_price:.8f} (Ø§Ù„Ù‡Ø¯Ù: ${current_target:.8f})\n"
                           f"ğŸ“Š Ø§Ù„Ø±Ø¨Ø­: +{profit_pct:.2f}% ({profit_usdt:+.2f} USDT)")
                    try:
                        send_telegram_update(msg)
                        cur.execute("""
                            UPDATE signals
                            SET achieved_target = TRUE, closed_at = NOW(), profit_percentage = %s, closing_price = %s
                            WHERE id = %s AND closed_at IS NULL
                        """, (profit_pct, current_price, signal_id))
                        conn.commit()
                        logger.info(f"âœ… [Tracker] ØªÙ… Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„ØªÙˆØµÙŠØ© {symbol} (ID: {signal_id}) - ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ù‡Ø¯Ù.")
                    except Exception as update_err:
                        logger.error(f"âŒ [Tracker] Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ«/Ø¥Ø±Ø³Ø§Ù„ Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù‡Ø¯Ù Ù„Ù„ØªÙˆØµÙŠØ© {signal_id}: {update_err}")
                        if conn and not conn.closed: conn.rollback()
                    continue # Move to next signal

                # Check for Stop Loss Hit
                elif current_price <= current_stop_loss:
                    loss_pct = ((current_stop_loss / entry_price) - 1) * 100
                    loss_usdt = TRADE_VALUE * (loss_pct / 100)
                    # Check if stop loss was profitable (SL > entry price)
                    profitable_stop = current_stop_loss > entry_price
                    stop_type_msg = "ÙˆÙ‚Ù Ø®Ø³Ø§Ø±Ø© Ø±Ø§Ø¨Ø­" if profitable_stop else "ÙˆÙ‚Ù Ø®Ø³Ø§Ø±Ø©"
                    safe_symbol = symbol.replace('_', '\\_').replace('*', '\\*').replace('[', '\\[').replace('`', '\\`')
                    msg = (f"ğŸ›‘ **{stop_type_msg}** ğŸ›‘\n"
                           f"ğŸ“‰ Ø§Ù„Ø²ÙˆØ¬: `{safe_symbol}` (ID: {signal_id})\n"
                           f"ğŸ’° Ø£ØºÙ„Ù‚ Ø¹Ù†Ø¯: ${current_price:.8f} (Ø§Ù„ÙˆÙ‚Ù: ${current_stop_loss:.8f})\n"
                           f"ğŸ“Š Ø§Ù„Ù†ØªÙŠØ¬Ø©: {loss_pct:.2f}% ({loss_usdt:.2f} USDT)")
                    try:
                        send_telegram_update(msg)
                        cur.execute("""
                            UPDATE signals
                            SET hit_stop_loss = TRUE, closed_at = NOW(), profit_percentage = %s, profitable_stop_loss = %s, closing_price = %s
                            WHERE id = %s AND closed_at IS NULL
                        """, (loss_pct, profitable_stop, current_price, signal_id))
                        conn.commit()
                        logger.info(f"âœ… [Tracker] ØªÙ… Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„ØªÙˆØµÙŠØ© {symbol} (ID: {signal_id}) - {stop_type_msg}.")
                    except Exception as update_err:
                        logger.error(f"âŒ [Tracker] Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ«/Ø¥Ø±Ø³Ø§Ù„ Ø¥ØºÙ„Ø§Ù‚ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ù„Ù„ØªÙˆØµÙŠØ© {signal_id}: {update_err}")
                        if conn and not conn.closed: conn.rollback()
                    continue # Move to next signal

                # Check for Trailing Stop Loss Activation & Update (only if not already hit target/SL)
                # Fetch data for ATR calculation on the tracking timeframe
                df_track = fetch_historical_data(symbol, interval=SIGNAL_TRACKING_TIMEFRAME, days=SIGNAL_TRACKING_LOOKBACK_DAYS)

                if df_track is None or df_track.empty or len(df_track) < 20: # Need enough data for ATR period
                    logger.warning(f"âš ï¸ [Tracker] Ø¨ÙŠØ§Ù†Ø§Øª {SIGNAL_TRACKING_TIMEFRAME} ØºÙŠØ± ÙƒØ§ÙÙŠØ©/Ù…ØªØ§Ø­Ø© Ù„Ø­Ø³Ø§Ø¨ ATR Ù„Ù„Ø²ÙˆØ¬ {symbol} (ID: {signal_id}). ØªØ®Ø·ÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ.")
                    continue # Skip trailing stop update for this cycle

                df_track = calculate_atr_indicator(df_track, period=14) # Use standard 14 period ATR

                if 'atr' not in df_track.columns or df_track['atr'].iloc[-1] is None or pd.isna(df_track['atr'].iloc[-1]):
                     logger.warning(f"âš ï¸ [Tracker] ÙØ´Ù„ ÙÙŠ Ø­Ø³Ø§Ø¨ ATR Ù„Ù„Ø²ÙˆØ¬ {symbol} (ID: {signal_id}) Ø¹Ù„Ù‰ ÙØ±ÙŠÙ… {SIGNAL_TRACKING_TIMEFRAME}.")
                     continue # Skip trailing stop update

                current_atr = df_track['atr'].iloc[-1]
                if current_atr <= 0:
                    logger.warning(f"âš ï¸ [Tracker] Ù‚ÙŠÙ…Ø© ATR ØºÙŠØ± ØµØ§Ù„Ø­Ø© ({current_atr}) Ù„Ù„Ø²ÙˆØ¬ {symbol} (ID: {signal_id}).")
                    continue # Skip trailing stop update

                current_gain_pct = (current_price / entry_price) - 1 # Calculate gain percentage

                # Activate trailing stop logic only if profit threshold is met
                if current_gain_pct >= TRAILING_STOP_ACTIVATION_PROFIT_PCT:
                    # Calculate potential new stop loss based on ATR
                    potential_new_stop_loss = current_price - (TRAILING_STOP_ATR_MULTIPLIER * current_atr)

                    # Update stop loss only if the potential new SL is higher than the current SL
                    # and higher than the initial stop loss (to prevent moving SL down initially)
                    # and ensure it's at least break-even or better if desired (optional check: potential_new_stop_loss > entry_price)
                    if potential_new_stop_loss > current_stop_loss:
                        # Safety check: Don't set SL above current price
                        new_stop_loss = min(potential_new_stop_loss, current_price * 0.999) # Keep a tiny gap

                        # Make sure the new stop loss is actually an improvement
                        if new_stop_loss > current_stop_loss:
                            logger.info(f"  => [Tracker] ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ Ù„Ù„Ø²ÙˆØ¬ {symbol} (ID: {signal_id})!")
                            logger.info(f"     Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯: {new_stop_loss:.8f} (Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ - {TRAILING_STOP_ATR_MULTIPLIER:.1f} * ATR)")
                            safe_symbol = symbol.replace('_', '\\_').replace('*', '\\*').replace('[', '\\[').replace('`', '\\`')
                            update_msg = (
                                f"ğŸ”„ **ØªØ­Ø¯ÙŠØ« ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© (Ù…ØªØ­Ø±Ùƒ)** ğŸ”„\n"
                                f"ğŸ“ˆ Ø§Ù„Ø²ÙˆØ¬: `{safe_symbol}` (ID: {signal_id})\n"
                                f"   - Ø³Ø¹Ø± Ø§Ù„Ø¯Ø®ÙˆÙ„: ${entry_price:.8f}\n"
                                f"   - Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ: ${current_price:.8f} ({current_gain_pct:+.2%})\n"
                                f"   - Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù‚Ø¯ÙŠÙ…: ${current_stop_loss:.8f}\n"
                                f"   - **Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯:** `${new_stop_loss:.8f}` âœ…"
                            )
                            try:
                                send_telegram_update(update_msg)
                                cur.execute("""
                                    UPDATE signals
                                    SET current_stop_loss = %s, is_trailing_active = TRUE
                                    WHERE id = %s AND closed_at IS NULL
                                """, (new_stop_loss, signal_id))
                                conn.commit()
                                logger.info(f"âœ… [Tracker] ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ Ù„Ù„ØªÙˆØµÙŠØ© {symbol} (ID: {signal_id}) Ø¥Ù„Ù‰ {new_stop_loss:.8f}")
                            except Exception as update_err:
                                 logger.error(f"âŒ [Tracker] Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ«/Ø¥Ø±Ø³Ø§Ù„ ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ Ù„Ù„ØªÙˆØµÙŠØ© {signal_id}: {update_err}")
                                 if conn and not conn.closed: conn.rollback()
                        else:
                             logger.debug(f"  [Tracker] Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ Ø§Ù„Ù…Ø­ØªÙ…Ù„ ({new_stop_loss:.8f}) Ù„ÙŠØ³ Ø£ÙØ¶Ù„ Ù…Ù† Ø§Ù„Ø­Ø§Ù„ÙŠ ({current_stop_loss:.8f}) Ù„Ù€ {symbol} (ID: {signal_id}).")
                    # else: No need to log if potential SL is not higher
                # else: Profit threshold not met, don't activate/update trailing stop yet

            logger.info("==========================================") # End of loop iteration log

        except psycopg2.Error as db_err:
            logger.error(f"âŒ [Tracker] Ø®Ø·Ø£ DB Ø£Ø«Ù†Ø§Ø¡ Ø­Ù„Ù‚Ø© Ø§Ù„ØªØªØ¨Ø¹: {db_err}")
            if conn and not conn.closed: conn.rollback()
            time.sleep(60) # Longer sleep on DB error
        except Exception as e:
            logger.error(f"âŒ [Tracker] Ø­Ø¯Ø« Ø®Ø·Ø£ Ø¹Ø§Ù… Ø£Ø«Ù†Ø§Ø¡ ØªØªØ¨Ø¹ Ø§Ù„ØªÙˆØµÙŠØ§Øª: {e}", exc_info=True)
            # Consider adding more specific error handling if needed
            time.sleep(60) # Longer sleep on general error

        # Wait before the next tracking cycle
        time.sleep(30) # Check active signals every 30 seconds

# ---------------------- *** ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙˆÙ‚ (Ù…ÙØ­Ø¯ÙÙ‘Ø«) *** ----------------------
def analyze_market():
    """ÙŠØ­Ù„Ù„ Ø§Ù„Ø³ÙˆÙ‚ Ø¨Ø­Ø«Ù‹Ø§ Ø¹Ù† ÙØ±Øµ ØªØ¯Ø§ÙˆÙ„ Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ÙˆÙŠØªØ¶Ù…Ù† ØªÙ†Ø¨Ø¤ LR."""
    logger.info("==========================================")
    logger.info(f" H [Market Analysis] Ø¨Ø¯Ø¡ Ø¯ÙˆØ±Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙˆÙ‚ (Ø§Ù„ÙØ±ÙŠÙ…: {SIGNAL_GENERATION_TIMEFRAME}, Ø¨ÙŠØ§Ù†Ø§Øª: {SIGNAL_GENERATION_LOOKBACK_DAYS} ÙŠÙˆÙ…)...")

    if not can_generate_new_recommendation():
        logger.info(" H [Market Analysis] ØªÙ… ØªØ®Ø·ÙŠ Ø§Ù„Ø¯ÙˆØ±Ø©: ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©.")
        return

    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini API (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ø£Ùˆ Ù‚ÙŠÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
    btc_dominance, eth_dominance = 0.0, 0.0 # Default values
    try:
        # Comment out if not using Gemini or if it causes issues
        btc_dominance, eth_dominance = calculate_market_dominance()
        logger.info(f" H [Market Analysis] Ù†Ø³Ø¨ Ø§Ù„Ø³ÙŠØ·Ø±Ø© (Gemini): BTC {btc_dominance:.2f}%, ETH {eth_dominance:.2f}%")
    except Exception as dom_err:
        logger.warning(f"âš ï¸ [Market Analysis] ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ù†Ø³Ø¨ Ø³ÙŠØ·Ø±Ø© Ø§Ù„Ø³ÙˆÙ‚: {dom_err}. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© (0.0).")
        btc_dominance, eth_dominance = 0.0, 0.0 # Fallback to defaults

    symbols_to_analyze = get_crypto_symbols()
    if not symbols_to_analyze:
        logger.warning("âš ï¸ [Market Analysis] Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ù…ÙˆØ² ÙØ§Ø±ØºØ©. Ù„Ø§ ÙŠÙ…ÙƒÙ† Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„.")
        return

    logger.info(f" H [Market Analysis] Ø³ÙŠØªÙ… ØªØ­Ù„ÙŠÙ„ {len(symbols_to_analyze)} Ø²ÙˆØ¬ Ø¹Ù…Ù„Ø§Øª...")
    generated_signals_count = 0
    processed_symbols_count = 0

    for symbol in symbols_to_analyze:
        processed_symbols_count += 1
        if not can_generate_new_recommendation():
             logger.info(f" H [Market Analysis] ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„ØµÙÙ‚Ø§Øª Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ({MAX_OPEN_TRADES}). Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±Ù…ÙˆØ² Ø¬Ø¯ÙŠØ¯Ø©.")
             break # Stop analyzing more symbols in this cycle

        logger.debug(f" H [Market Analysis] ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²ÙˆØ¬: {symbol} ({processed_symbols_count}/{len(symbols_to_analyze)})...")

        try:
            check_db_connection()
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ ØªÙˆØµÙŠØ© Ù…ÙØªÙˆØ­Ø© Ø¨Ø§Ù„ÙØ¹Ù„ Ù„Ù‡Ø°Ø§ Ø§Ù„Ø²ÙˆØ¬
            cur.execute("SELECT COUNT(*) FROM signals WHERE symbol = %s AND closed_at IS NULL", (symbol,))
            if cur.fetchone()[0] > 0:
                logger.debug(f" H [Market Analysis] ØªØ®Ø·ÙŠ {symbol}: ØªÙˆØ¬Ø¯ ØªÙˆØµÙŠØ© Ù†Ø´Ø·Ø© Ø¨Ø§Ù„ÙØ¹Ù„.")
                continue # Skip this symbol, already have an open trade
        except Exception as db_check_err:
             logger.error(f"âŒ [Market Analysis] Ø®Ø·Ø£ DB Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆØµÙŠØ© Ø­Ø§Ù„ÙŠØ© Ù„Ù€ {symbol}: {db_check_err}")
             if conn and not conn.closed: conn.rollback()
             continue # Skip this symbol due to DB error

        # Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©
        df_signal_gen = fetch_historical_data(symbol, interval=SIGNAL_GENERATION_TIMEFRAME, days=SIGNAL_GENERATION_LOOKBACK_DAYS)
        if df_signal_gen is None or df_signal_gen.empty:
            logger.debug(f" H [Market Analysis] ØªØ®Ø·ÙŠ {symbol}: Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© ({SIGNAL_GENERATION_TIMEFRAME}, {SIGNAL_GENERATION_LOOKBACK_DAYS}d).")
            continue # Skip if no data

        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© ÙˆØ§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ
        signal = generate_signal_using_freqtrade_strategy(df_signal_gen, symbol)

        if signal:
            try:
                # Ø¬Ù„Ø¨ Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ø£Ø®ÙŠØ± Ù‚Ø¨Ù„ Ø§Ù„Ø­ÙØ¸ ÙˆØ§Ù„Ø¥Ø±Ø³Ø§Ù„
                volume_15m = fetch_recent_volume(symbol)

                # *** Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ø£Ø¯Ù†Ù‰ ***
                if volume_15m < MIN_VOLUME_15M_USDT:
                    logger.info(f" H [Market Analysis] ØªÙ… Ø±ÙØ¶ Ø¥Ø´Ø§Ø±Ø© {symbol}. Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ ({volume_15m:,.0f} USDT) Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ ({MIN_VOLUME_15M_USDT:,.0f} USDT).")
                    continue # Skip signal due to low volume

                # Ø­ÙØ¸ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                check_db_connection()
                cur.execute("""
                    INSERT INTO signals (
                        symbol, entry_price, initial_target, initial_stop_loss,
                        current_target, current_stop_loss, r2_score, volume_15m,
                        predicted_price_lr, r2_score_lr -- *** NEW COLUMNS
                    )
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s) -- *** Added placeholders
                """, (
                    signal['symbol'], signal['entry_price'], signal['initial_target'], signal['initial_stop_loss'],
                    signal['current_target'], signal['current_stop_loss'], signal['r2_score'], volume_15m,
                    signal['predicted_price_lr'], signal['r2_score_lr'] # *** Added values
                ))
                conn.commit()
                generated_signals_count += 1
                logger.info(f"âœ… [Market Analysis] ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ø²ÙˆØ¬ {symbol} ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")

                # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡ Ø¹Ø¨Ø± ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…
                # Ù†Ù…Ø±Ø± Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø­Ø³ÙˆØ¨ ÙˆØ§Ù„Ø³ÙŠØ·Ø±Ø©
                send_telegram_alert(signal, volume_15m, btc_dominance, eth_dominance, SIGNAL_GENERATION_TIMEFRAME)

            except psycopg2.Error as insert_err:
                logger.error(f"âŒ [Market Analysis] Ø®Ø·Ø£ DB Ø£Ø«Ù†Ø§Ø¡ Ø­ÙØ¸ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù„Ù„Ø²ÙˆØ¬ {symbol}: {insert_err}")
                if conn and not conn.closed: conn.rollback() # Rollback on insertion error
            except Exception as general_err:
                logger.error(f"âŒ [Market Analysis] Ø®Ø·Ø£ Ø¹Ø§Ù… Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø©/Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø§Ø±Ø© {symbol}: {general_err}", exc_info=True)
                # Consider rolling back DB if the error happened after insertion attempt but before commit?
                # If autocommit is False (which it is), commit only happens if no error occurs before it.
                # So, rollback might not be strictly necessary here unless commit itself failed partially.
                if conn and not conn.closed: conn.rollback()

    logger.info(f"âœ… [Market Analysis] Ø§Ù†ØªÙ‡Øª Ø¯ÙˆØ±Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„. ØªÙ… ØªÙˆÙ„ÙŠØ¯ {generated_signals_count} Ø¥Ø´Ø§Ø±Ø©/Ø¥Ø´Ø§Ø±Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ù…Ù† {processed_symbols_count} Ø²ÙˆØ¬ ØªÙ… ØªØ­Ù„ÙŠÙ„Ù‡.")

# (Ø¯Ø§Ù„Ø© can_generate_new_recommendation ÙƒÙ…Ø§ Ù‡ÙŠ)
def can_generate_new_recommendation():
    """ØªØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠÙ…ÙƒÙ† ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ© Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø­Ø¯ MAX_OPEN_TRADES."""
    try:
        check_db_connection() # Ensure connection is live
        cur.execute("SELECT COUNT(*) FROM signals WHERE closed_at IS NULL")
        active_count = cur.fetchone()[0]
        if active_count < MAX_OPEN_TRADES:
            logger.debug(f"âœ… [Gate] Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø© ({active_count}) < Ø§Ù„Ø­Ø¯ ({MAX_OPEN_TRADES}). ÙŠÙ…ÙƒÙ† ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø¬Ø¯ÙŠØ¯Ø©.")
            return True
        else:
            logger.info(f"âš ï¸ [Gate] ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ ({MAX_OPEN_TRADES}) Ù„Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©. Ø¥ÙŠÙ‚Ø§Ù ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø¤Ù‚ØªÙ‹Ø§.")
            return False
    except psycopg2.Error as db_err:
         logger.error(f"âŒ [Gate] Ø®Ø·Ø£ DB Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©: {db_err}")
         if conn and not conn.closed: conn.rollback() # Rollback potentially uncommitted transaction
         return False # Assume cannot generate if DB error occurs
    except Exception as e:
        logger.error(f"âŒ [Gate] Ø®Ø·Ø£ Ø¹Ø§Ù… Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©: {e}")
        return False # Assume cannot generate on general error

# ---------------------- Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ----------------------
if __name__ == '__main__':
    # ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„Ø§Ù‹
    try:
        init_db()
    except Exception as e:
        logger.critical(f"âŒ [Main] ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø´ÙƒÙ„ Ù‚Ø§ØªÙ„: {e}")
        exit(1) # Exit if DB connection fails critically on startup

    # Ø¥Ø¹Ø¯Ø§Ø¯ Webhook (Ø¨Ø¹Ø¯ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ ØªÙˆÙƒÙ† ØªÙ„ÙŠØ¬Ø±Ø§Ù…)
    if telegram_token:
        set_telegram_webhook()
    else:
        logger.warning("âš ï¸ [Main] Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØªÙˆÙƒÙ† ØªÙ„ÙŠØ¬Ø±Ø§Ù…. ØªØ®Ø·ÙŠ Ø¥Ø¹Ø¯Ø§Ø¯ Webhook.")

    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†ÙØ° ÙˆØªØ´ØºÙŠÙ„ Flask
    port = int(os.environ.get("PORT", 5000)) # Default to 5000 if PORT not set
    flask_thread = Thread(target=lambda: app.run(host="0.0.0.0", port=port, use_reloader=False), name="FlaskThread", daemon=True)
    flask_thread.start()
    logger.info(f"âœ… [Main] ØªÙ… Ø¨Ø¯Ø¡ Ø®ÙŠØ· Ø®Ø§Ø¯Ù… Flask Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†ÙØ° {port}.")

    time.sleep(2) # Give Flask a moment to start

    # Ø¨Ø¯Ø¡ Ø®ÙŠØ· WebSocket (Ø¨Ø¹Ø¯ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…ÙØ§ØªÙŠØ­ Binance)
    if api_key and api_secret:
        websocket_thread = Thread(target=run_ticker_socket_manager, name="WebSocketThread", daemon=True)
        websocket_thread.start()
        logger.info("âœ… [Main] ØªÙ… Ø¨Ø¯Ø¡ Ø®ÙŠØ· Ù…Ø¯ÙŠØ± WebSocket.")
        logger.info("â„¹ï¸ [Main] Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ù€ 15 Ø«Ø§Ù†ÙŠØ© Ù„Ù€ WebSocket Ù„Ù„Ø§ØªØµØ§Ù„ ÙˆØ§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ©...")
        time.sleep(15) # Wait for WS connection and initial data
    else:
        logger.warning("âš ï¸ [Main] Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙØ§ØªÙŠØ­ Binance API. Ù„Ù† ÙŠØªÙ… ØªØ´ØºÙŠÙ„ WebSocket Ø£Ùˆ Ø§Ù„ØªØªØ¨Ø¹.")
        websocket_thread = None # Ensure thread object is None
        ticker_data = {} # Ensure ticker_data is empty

    # Ø¨Ø¯Ø¡ Ø®ÙŠØ· Ø§Ù„ØªØªØ¨Ø¹ (ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† WebSocket ÙŠØ¹Ù…Ù„)
    if websocket_thread and websocket_thread.is_alive():
        tracker_thread = Thread(target=track_signals, name="TrackerThread", daemon=True)
        tracker_thread.start()
        logger.info("âœ… [Main] ØªÙ… Ø¨Ø¯Ø¡ Ø®ÙŠØ· ØªØªØ¨Ø¹ Ø§Ù„ØªÙˆØµÙŠØ§Øª.")
    else:
        logger.warning("âš ï¸ [Main] Ù„Ù† ÙŠØªÙ… ØªØ´ØºÙŠÙ„ Ø®ÙŠØ· Ø§Ù„ØªØªØ¨Ø¹ Ù„Ø£Ù† WebSocket ØºÙŠØ± Ù†Ø´Ø·.")
        tracker_thread = None # Ensure thread object is None

    # Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØ¬Ø¯ÙˆÙ„Ø© Ø§Ù„Ù…Ù‡Ø§Ù… (ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† WebSocket Ùˆ Tracker ÙŠØ¹Ù…Ù„Ø§Ù†)
    scheduler = None
    if tracker_thread and tracker_thread.is_alive():
        try:
            scheduler = BackgroundScheduler(timezone="UTC")
            # Ø¬Ø¯ÙˆÙ„Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙˆÙ‚ - ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„ÙØ§ØµÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ Ù…Ø¹Ù‚ÙˆÙ„ (e.g., 5 or 15 minutes)
            scheduler.add_job(analyze_market, 'interval', minutes=15, id='market_analyzer', replace_existing=True, misfire_grace_time=120) # Check every 15 mins
            logger.info("âœ… [Main] ØªÙ… Ø¬Ø¯ÙˆÙ„Ø© Ù…Ù‡Ù…Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙˆÙ‚ (ÙƒÙ„ 15 Ø¯Ù‚ÙŠÙ‚Ø©).")
            # --- ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ù…Ù‡Ø§Ù… Ù…Ø¬Ø¯ÙˆÙ„Ø© Ø£Ø®Ø±Ù‰ Ù‡Ù†Ø§ ---
            # Ù…Ø«Ø§Ù„: Ø¥Ø±Ø³Ø§Ù„ ØªÙ‚Ø±ÙŠØ± ÙŠÙˆÙ…ÙŠ
            # scheduler.add_job(send_report, 'cron', hour=8, minute=0, args=[chat_id], id='daily_report') # Daily report at 8:00 UTC
            # logger.info("âœ… [Main] ØªÙ… Ø¬Ø¯ÙˆÙ„Ø© Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙŠÙˆÙ…ÙŠ.")

            scheduler.start()
            logger.info("âœ… [Main] ØªÙ… Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ APScheduler.")
        except Exception as sched_err:
            logger.error(f"âŒ [Main] ÙØ´Ù„ ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯ Ø£Ùˆ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„: {sched_err}")
            scheduler = None # Ensure scheduler object is None if setup failed
    else:
        logger.warning("âš ï¸ [Main] Ù„Ù† ÙŠØªÙ… ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„ Ù„Ø£Ù† Ø§Ù„Ù…ØªØªØ¨Ø¹ ØºÙŠØ± Ù†Ø´Ø·.")

    logger.info("==========================================")
    logger.info("âœ… Ø§Ù„Ù†Ø¸Ø§Ù… Ù…ØªØµÙ„ ÙˆÙŠØ¹Ù…Ù„ Ø§Ù„Ø¢Ù† (Ø£Ùˆ ÙŠØ­Ø§ÙˆÙ„)")
    logger.info("==========================================")

    # Ø­Ù„Ù‚Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø®ÙŠÙˆØ·
    try:
        while True:
            # Check Flask thread
            if not flask_thread or not flask_thread.is_alive():
                 logger.critical("âŒ [Main] ØªÙˆÙ‚Ù Ø®ÙŠØ· Flask! Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø© Ø­Ø§Ù„ÙŠÙ‹Ø§. Ø§Ù„Ø®Ø±ÙˆØ¬.")
                 # In a real scenario, you might try to restart Flask or handle cleanup
                 break # Exit the loop

            # Check WebSocket thread only if it was supposed to start
            if api_key and api_secret and (not websocket_thread or not websocket_thread.is_alive()):
                 logger.critical("âŒ [Main] ØªÙˆÙ‚Ù Ø®ÙŠØ· WebSocket! Ù‡Ø°Ø§ Ø³ÙŠØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø§Ù„ØªØªØ¨Ø¹ ÙˆØ§Ù„ØªÙˆØµÙŠØ§Øª. Ø§Ù„Ø®Ø±ÙˆØ¬.")
                 # Attempting restart is complex; exiting is safer for now.
                 break # Exit the loop

            # Check Tracker thread only if it was supposed to start
            if websocket_thread and (not tracker_thread or not tracker_thread.is_alive()):
                 logger.critical("âŒ [Main] ØªÙˆÙ‚Ù Ø®ÙŠØ· ØªØªØ¨Ø¹ Ø§Ù„ØªÙˆØµÙŠØ§Øª! Ø§Ù„Ø®Ø±ÙˆØ¬.")
                 break # Exit the loop

            # Check Scheduler status only if it was supposed to start
            if tracker_thread and scheduler and not scheduler.running:
                logger.warning("âš ï¸ [Main] Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„ (APScheduler) Ù„Ø§ ÙŠØ¹Ù…Ù„!")
                # You might try restarting it, but background scheduler issues can be tricky.
                # For now, just log the warning.

            time.sleep(30) # Check thread health every 30 seconds

    except KeyboardInterrupt:
        logger.info("ğŸ›‘ [Main] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø·Ù„Ø¨ Ø¥ÙŠÙ‚Ø§Ù (Ctrl+C). Ø¬Ø§Ø±ÙŠ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ´ØºÙŠÙ„...")
    except Exception as main_loop_err:
        logger.error(f"âŒ [Main] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø­Ù„Ù‚Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: {main_loop_err}", exc_info=True)
    finally:
        # Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„ Ø¨Ø£Ù…Ø§Ù†
        if scheduler and scheduler.running:
            try:
                scheduler.shutdown()
                logger.info("âœ… [Main] ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„ (APScheduler).")
            except Exception as sched_down_err:
                logger.error(f"âŒ [Main] Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„: {sched_down_err}")

        # Ø¥ÙŠÙ‚Ø§Ù WebSocket Manager (Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ¹Ù…Ù„)
        # Note: Stopping ThreadedWebsocketManager directly isn't straightforward from outside.
        # relies on daemon threads exiting when the main thread finishes.

        # Ø¥ØºÙ„Ø§Ù‚ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        if cur:
            cur.close()
            logger.info("âœ… [Main] ØªÙ… Ø¥ØºÙ„Ø§Ù‚ Ù…Ø¤Ø´Ø± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
        if conn:
            conn.close()
            logger.info("âœ… [Main] ØªÙ… Ø¥ØºÙ„Ø§Ù‚ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")

        logger.info("ğŸ‘‹ [Main] Ø§ÙƒØªÙ…Ù„ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ´ØºÙŠÙ„.")
        # Allow daemon threads to potentially finish logging etc.
        time.sleep(2)
